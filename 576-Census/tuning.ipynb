{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from utils import load_datasets, load_target\n",
    "import models\n",
    "from models.tuning import beyesian_optimization\n",
    "from models.evaluation import cross_validation_score\n",
    "import json\n",
    "\n",
    "n_trials = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config/default.json'))\n",
    "# X_train, X_test = load_datasets([\"Age\", \"AgeSplit\", \"EducationNum\"])\n",
    "X_train, X_test = load_datasets(config['features'])\n",
    "y_train = load_target('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 08:58:42,983]\u001b[0m A new study created in memory with name: no-name-89fa72d5-a5c9-40f3-854f-bfdf89f9b8de\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:58:47,857]\u001b[0m Trial 0 finished with value: 4.221461400768562 and parameters: {'learning_rate': 0.055332536888805156, 'lambda_l1': 7.151893666572301, 'lambda_l2': 6.0276337646888045, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 0 with value: 4.221461400768562.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:58:52,597]\u001b[0m Trial 1 finished with value: 4.3004727187927765 and parameters: {'learning_rate': 0.06494351719359896, 'lambda_l1': 4.375872118251053, 'lambda_l2': 8.917730008903067, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 0 with value: 4.221461400768562.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:58:56,704]\u001b[0m Trial 2 finished with value: 4.029578003153976 and parameters: {'learning_rate': 0.0793807787701838, 'lambda_l1': 5.2889492022400955, 'lambda_l2': 5.680445615258877, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:07,009]\u001b[0m Trial 3 finished with value: 4.661664889058793 and parameters: {'learning_rate': 0.00962580067045253, 'lambda_l1': 0.2021839842010732, 'lambda_l2': 8.32619845715318, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:10,467]\u001b[0m Trial 4 finished with value: 4.119876241700243 and parameters: {'learning_rate': 0.09788321588104364, 'lambda_l1': 7.991585644175649, 'lambda_l2': 4.6147936279145245, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:13,510]\u001b[0m Trial 5 finished with value: 4.571368218350625 and parameters: {'learning_rate': 0.06435218111142486, 'lambda_l1': 1.433532882656931, 'lambda_l2': 9.44668917104915, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:16,029]\u001b[0m Trial 6 finished with value: 4.097300832818039 and parameters: {'learning_rate': 0.027191005598358072, 'lambda_l1': 7.742336896599829, 'lambda_l2': 4.561503327603981, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:18,691]\u001b[0m Trial 7 finished with value: 4.153738048491799 and parameters: {'learning_rate': 0.062145914210511834, 'lambda_l1': 6.120957231103256, 'lambda_l2': 6.1693399725782285, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:21,617]\u001b[0m Trial 8 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.036591282156804815, 'lambda_l1': 4.370319543623094, 'lambda_l2': 6.976311962296336, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:24,164]\u001b[0m Trial 9 finished with value: 4.402058400473795 and parameters: {'learning_rate': 0.06739314909219779, 'lambda_l1': 2.103825618634583, 'lambda_l2': 1.2892629852592699, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:26,707]\u001b[0m Trial 10 finished with value: 4.176313979986701 and parameters: {'learning_rate': 0.05744948027137009, 'lambda_l1': 4.386015140237188, 'lambda_l2': 9.883738380708524, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:29,440]\u001b[0m Trial 11 finished with value: 4.074726991773934 and parameters: {'learning_rate': 0.01696964227061463, 'lambda_l1': 6.531083258122901, 'lambda_l2': 2.5329160328649047, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:33,994]\u001b[0m Trial 12 finished with value: 4.435919423346301 and parameters: {'learning_rate': 0.016737988780906453, 'lambda_l1': 1.1037514205392998, 'lambda_l2': 6.563295898089438, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:36,459]\u001b[0m Trial 13 finished with value: 4.153737264572749 and parameters: {'learning_rate': 0.03750379189543545, 'lambda_l1': 8.209932300269418, 'lambda_l2': 0.9710127669595999, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:38,894]\u001b[0m Trial 14 finished with value: 4.165026798158299 and parameters: {'learning_rate': 0.09766948703632619, 'lambda_l1': 4.686512021790503, 'lambda_l2': 9.767610882135761, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:43,475]\u001b[0m Trial 15 finished with value: 4.232749889128712 and parameters: {'learning_rate': 0.004879591433177747, 'lambda_l1': 2.828069632936026, 'lambda_l2': 1.2019656209297234, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:46,465]\u001b[0m Trial 16 finished with value: 4.244036809650765 and parameters: {'learning_rate': 0.03248033476000363, 'lambda_l1': 4.14262995100407, 'lambda_l2': 0.6414749728463687, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:50,975]\u001b[0m Trial 17 finished with value: 4.300474809243573 and parameters: {'learning_rate': 0.0272735596030051, 'lambda_l1': 5.2324805394345155, 'lambda_l2': 0.9394051166450116, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:55,137]\u001b[0m Trial 18 finished with value: 4.119875457781194 and parameters: {'learning_rate': 0.032538326292681045, 'lambda_l1': 6.674103802962713, 'lambda_l2': 1.3179786327259428, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 08:59:58,311]\u001b[0m Trial 19 finished with value: 4.108588798565491 and parameters: {'learning_rate': 0.01913594483870457, 'lambda_l1': 5.8651293522357015, 'lambda_l2': 0.20107547167386003, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:03,493]\u001b[0m Trial 20 finished with value: 4.165025230320201 and parameters: {'learning_rate': 0.06810383714282678, 'lambda_l1': 2.7000797392215685, 'lambda_l2': 7.351940223874008, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:07,485]\u001b[0m Trial 21 finished with value: 4.210175264165558 and parameters: {'learning_rate': 0.058039576107365855, 'lambda_l1': 5.92041931679797, 'lambda_l2': 5.7225190621862145, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:10,616]\u001b[0m Trial 22 finished with value: 4.210175264165558 and parameters: {'learning_rate': 0.04526541248314511, 'lambda_l1': 8.464086726247192, 'lambda_l2': 6.994792756180249, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:15,186]\u001b[0m Trial 23 finished with value: 4.131163162222294 and parameters: {'learning_rate': 0.040254068343851486, 'lambda_l1': 8.811031972300585, 'lambda_l2': 5.8127287305458575, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:20,299]\u001b[0m Trial 24 finished with value: 4.277898093829622 and parameters: {'learning_rate': 0.07280017370214442, 'lambda_l1': 5.013243824253778, 'lambda_l2': 9.560836347671403, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:29,040]\u001b[0m Trial 25 finished with value: 5.158306638248184 and parameters: {'learning_rate': 0.061032928198664516, 'lambda_l1': 0.19193199290140325, 'lambda_l2': 3.0157481737297447, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:33,251]\u001b[0m Trial 26 finished with value: 4.289185798270723 and parameters: {'learning_rate': 0.06218352747088532, 'lambda_l1': 4.287687015169974, 'lambda_l2': 1.3547406508697615, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:37,008]\u001b[0m Trial 27 finished with value: 4.198887821030807 and parameters: {'learning_rate': 0.05949640336356915, 'lambda_l1': 5.743252492752535, 'lambda_l2': 6.532008202039328, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:41,569]\u001b[0m Trial 28 finished with value: 4.266613525064717 and parameters: {'learning_rate': 0.08975811298925525, 'lambda_l1': 3.675618706803346, 'lambda_l2': 4.358649258297619, 'bagging_freq': 7, 'min_child_samples': 82}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:47,626]\u001b[0m Trial 29 finished with value: 4.81968935425167 and parameters: {'learning_rate': 0.07068496977049626, 'lambda_l1': 1.0022688821207422, 'lambda_l2': 9.19482613825191, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:52,591]\u001b[0m Trial 30 finished with value: 4.153737787185449 and parameters: {'learning_rate': 0.01579538216114138, 'lambda_l1': 8.681260575000882, 'lambda_l2': 1.6249293551388186, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:55,734]\u001b[0m Trial 31 finished with value: 4.131162639609595 and parameters: {'learning_rate': 0.08495281470290121, 'lambda_l1': 8.073189589176918, 'lambda_l2': 5.691007390454925, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:00:58,211]\u001b[0m Trial 32 finished with value: 4.187602207040503 and parameters: {'learning_rate': 0.07004544854131181, 'lambda_l1': 4.535426832245261, 'lambda_l2': 7.220555997482923, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:06,933]\u001b[0m Trial 33 finished with value: 5.079295842836669 and parameters: {'learning_rate': 0.08572453089686849, 'lambda_l1': 0.11714085173287886, 'lambda_l2': 3.599780651183858, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:13,577]\u001b[0m Trial 34 finished with value: 4.695528524994798 and parameters: {'learning_rate': 0.0525826240142088, 'lambda_l1': 0.5433798928491564, 'lambda_l2': 1.9999652569640354, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:18,357]\u001b[0m Trial 35 finished with value: 4.0521523668107795 and parameters: {'learning_rate': 0.023168544117977634, 'lambda_l1': 3.4535168135155097, 'lambda_l2': 9.280812935375096, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:22,249]\u001b[0m Trial 36 finished with value: 4.232749889128712 and parameters: {'learning_rate': 0.017304721493293363, 'lambda_l1': 6.214784018782851, 'lambda_l2': 5.77228589026939, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:25,899]\u001b[0m Trial 37 finished with value: 4.187600377896055 and parameters: {'learning_rate': 0.061782629640623705, 'lambda_l1': 5.356328034893255, 'lambda_l2': 5.89909976764661, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:30,151]\u001b[0m Trial 38 finished with value: 4.503645388686562 and parameters: {'learning_rate': 0.040423885159393096, 'lambda_l1': 2.0984374976527835, 'lambda_l2': 1.8619300669414314, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:34,052]\u001b[0m Trial 39 finished with value: 4.37948403681699 and parameters: {'learning_rate': 0.04955542205313914, 'lambda_l1': 2.274146287459086, 'lambda_l2': 2.5435648251603644, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:37,313]\u001b[0m Trial 40 finished with value: 4.074726730467584 and parameters: {'learning_rate': 0.031867792317416155, 'lambda_l1': 6.963434891191159, 'lambda_l2': 3.7775183991472905, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:42,401]\u001b[0m Trial 41 finished with value: 4.187600377896054 and parameters: {'learning_rate': 0.00765771351486161, 'lambda_l1': 6.793927738191745, 'lambda_l2': 4.536968451023484, 'bagging_freq': 4, 'min_child_samples': 91}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:46,647]\u001b[0m Trial 42 finished with value: 4.255323991479167 and parameters: {'learning_rate': 0.09904355579227374, 'lambda_l1': 2.168969851815769, 'lambda_l2': 6.630782034370226, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:51,306]\u001b[0m Trial 43 finished with value: 4.198888604949856 and parameters: {'learning_rate': 0.076079486729778, 'lambda_l1': 3.2001715150245067, 'lambda_l2': 3.8346389478843403, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:55,244]\u001b[0m Trial 44 finished with value: 4.232750411741412 and parameters: {'learning_rate': 0.06326920251552372, 'lambda_l1': 8.726506555747447, 'lambda_l2': 2.735420355420937, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:01:58,715]\u001b[0m Trial 45 finished with value: 4.074726991773934 and parameters: {'learning_rate': 0.09532637404022251, 'lambda_l1': 6.874882767003269, 'lambda_l2': 2.1550767789805074, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:03,008]\u001b[0m Trial 46 finished with value: 4.311760161927528 and parameters: {'learning_rate': 0.02614022261690756, 'lambda_l1': 2.1331197815416996, 'lambda_l2': 5.182007144124625, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:06,510]\u001b[0m Trial 47 finished with value: 4.334334786890682 and parameters: {'learning_rate': 0.043043861406399125, 'lambda_l1': 3.741699809600555, 'lambda_l2': 4.6357542490123524, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:10,934]\u001b[0m Trial 48 finished with value: 4.582654877566328 and parameters: {'learning_rate': 0.08652170498639991, 'lambda_l1': 1.175318568445012, 'lambda_l2': 5.17379107636735, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:14,745]\u001b[0m Trial 49 finished with value: 4.277898877748671 and parameters: {'learning_rate': 0.04020991057792209, 'lambda_l1': 5.654213122930876, 'lambda_l2': 1.8327983703079875, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:18,223]\u001b[0m Trial 50 finished with value: 4.221462184687611 and parameters: {'learning_rate': 0.03620566104714561, 'lambda_l1': 9.404319453123811, 'lambda_l2': 7.653252540416399, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:24,100]\u001b[0m Trial 51 finished with value: 4.142451389276095 and parameters: {'learning_rate': 0.009258821108759838, 'lambda_l1': 5.52192470370214, 'lambda_l2': 5.844760693712927, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:29,464]\u001b[0m Trial 52 finished with value: 4.650379536374839 and parameters: {'learning_rate': 0.024842049211629236, 'lambda_l1': 1.0029394316520386, 'lambda_l2': 0.16429630575044574, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:32,539]\u001b[0m Trial 53 finished with value: 4.323047343755929 and parameters: {'learning_rate': 0.07873013829029064, 'lambda_l1': 2.8173010647221894, 'lambda_l2': 5.864101665999165, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:35,145]\u001b[0m Trial 54 finished with value: 4.198888082337156 and parameters: {'learning_rate': 0.09777201883470024, 'lambda_l1': 8.765052454400855, 'lambda_l2': 3.3815895249868664, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:37,699]\u001b[0m Trial 55 finished with value: 4.176314502599401 and parameters: {'learning_rate': 0.09498256341915247, 'lambda_l1': 9.413777047651209, 'lambda_l2': 7.9920258755318905, 'bagging_freq': 5, 'min_child_samples': 88}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:40,885]\u001b[0m Trial 56 finished with value: 4.1424506053570465 and parameters: {'learning_rate': 0.03000900816627188, 'lambda_l1': 8.489435554639746, 'lambda_l2': 6.178766922996471, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:43,728]\u001b[0m Trial 57 finished with value: 4.198887037111757 and parameters: {'learning_rate': 0.01566594523386834, 'lambda_l1': 9.818293898364239, 'lambda_l2': 4.783703075616177, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:47,423]\u001b[0m Trial 58 finished with value: 4.503643820848463 and parameters: {'learning_rate': 0.03748987600683214, 'lambda_l1': 1.3690027254869863, 'lambda_l2': 8.221177333721277, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:54,465]\u001b[0m Trial 59 finished with value: 4.808400343278819 and parameters: {'learning_rate': 0.02320738586849919, 'lambda_l1': 0.9784448539618956, 'lambda_l2': 8.621915175594918, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:02:58,013]\u001b[0m Trial 60 finished with value: 4.176312412148603 and parameters: {'learning_rate': 0.09074899442289672, 'lambda_l1': 7.740473329245914, 'lambda_l2': 3.331451526954967, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:01,849]\u001b[0m Trial 61 finished with value: 4.300471934873727 and parameters: {'learning_rate': 0.023991180074923332, 'lambda_l1': 1.3248763562549533, 'lambda_l2': 0.5342718273339808, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:04,834]\u001b[0m Trial 62 finished with value: 4.560080252603173 and parameters: {'learning_rate': 0.07728749410177485, 'lambda_l1': 1.469466462534284, 'lambda_l2': 0.7952208350723367, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:08,606]\u001b[0m Trial 63 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.025291353775431635, 'lambda_l1': 4.205394672595589, 'lambda_l2': 5.573687917665481, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:11,547]\u001b[0m Trial 64 finished with value: 4.424634593275047 and parameters: {'learning_rate': 0.02776246261863275, 'lambda_l1': 1.314828001596448, 'lambda_l2': 0.5537432136582362, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:14,014]\u001b[0m Trial 65 finished with value: 4.221461923381261 and parameters: {'learning_rate': 0.04615791611324749, 'lambda_l1': 6.832813358643991, 'lambda_l2': 6.956254459432317, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:16,578]\u001b[0m Trial 66 finished with value: 4.10858932117819 and parameters: {'learning_rate': 0.018933945211953403, 'lambda_l1': 7.885455125179731, 'lambda_l2': 0.5684807737639223, 'bagging_freq': 5, 'min_child_samples': 79}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:19,087]\u001b[0m Trial 67 finished with value: 4.255323730172817 and parameters: {'learning_rate': 0.07796334862302656, 'lambda_l1': 2.5942256508593236, 'lambda_l2': 3.7381313855874825, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:21,820]\u001b[0m Trial 68 finished with value: 4.4810694571916585 and parameters: {'learning_rate': 0.03771442712257098, 'lambda_l1': 1.9705428098858533, 'lambda_l2': 4.5985588429615145, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:25,949]\u001b[0m Trial 69 finished with value: 4.255325559317265 and parameters: {'learning_rate': 0.00861868825167664, 'lambda_l1': 5.188351493126908, 'lambda_l2': 3.0681010023838597, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:30,448]\u001b[0m Trial 70 finished with value: 4.8422647631338736 and parameters: {'learning_rate': 0.06491145420114439, 'lambda_l1': 0.35362436720128476, 'lambda_l2': 4.304024400776587, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:33,006]\u001b[0m Trial 71 finished with value: 4.221461923381261 and parameters: {'learning_rate': 0.06845785854977995, 'lambda_l1': 2.7759609845416997, 'lambda_l2': 1.2886056633745961, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:35,589]\u001b[0m Trial 72 finished with value: 4.176312150842254 and parameters: {'learning_rate': 0.01952595828333363, 'lambda_l1': 9.039839550242531, 'lambda_l2': 5.438059505335204, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:38,023]\u001b[0m Trial 73 finished with value: 4.097302139349788 and parameters: {'learning_rate': 0.046401792215090006, 'lambda_l1': 7.2416763688737555, 'lambda_l2': 3.9902532230407664, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:40,524]\u001b[0m Trial 74 finished with value: 4.198886514499058 and parameters: {'learning_rate': 0.07026258337080116, 'lambda_l1': 3.2772040222939847, 'lambda_l2': 7.567786429801105, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:43,057]\u001b[0m Trial 75 finished with value: 4.097301878043438 and parameters: {'learning_rate': 0.016893343426040385, 'lambda_l1': 7.963914747209402, 'lambda_l2': 9.591666030760559, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:45,532]\u001b[0m Trial 76 finished with value: 4.210176570697307 and parameters: {'learning_rate': 0.0859145417751619, 'lambda_l1': 4.5722345389663355, 'lambda_l2': 9.518744768808617, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:47,963]\u001b[0m Trial 77 finished with value: 4.187599855283355 and parameters: {'learning_rate': 0.09097552812286111, 'lambda_l1': 8.15523818953045, 'lambda_l2': 1.5941446428954145, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:52,787]\u001b[0m Trial 78 finished with value: 4.142451650582446 and parameters: {'learning_rate': 0.007208582250311225, 'lambda_l1': 4.2403225246580964, 'lambda_l2': 2.586840676307236, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:55,279]\u001b[0m Trial 79 finished with value: 4.142450866663396 and parameters: {'learning_rate': 0.09593928946448389, 'lambda_l1': 3.5536884911656075, 'lambda_l2': 3.5670689104583597, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:03:57,666]\u001b[0m Trial 80 finished with value: 4.198888604949856 and parameters: {'learning_rate': 0.040724690579557264, 'lambda_l1': 9.292914173734225, 'lambda_l2': 0.9961493112165639, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:00,311]\u001b[0m Trial 81 finished with value: 4.10859010509724 and parameters: {'learning_rate': 0.04596207729384763, 'lambda_l1': 3.2670088244155915, 'lambda_l2': 2.327441300463127, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:05,805]\u001b[0m Trial 82 finished with value: 4.119877548231991 and parameters: {'learning_rate': 0.0025450003802359933, 'lambda_l1': 4.2879572306944205, 'lambda_l2': 0.6807407490664613, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:10,749]\u001b[0m Trial 83 finished with value: 4.5600820817476215 and parameters: {'learning_rate': 0.026065928178562344, 'lambda_l1': 1.310552320842025, 'lambda_l2': 0.12036223885618046, 'bagging_freq': 1, 'min_child_samples': 64}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:13,856]\u001b[0m Trial 84 finished with value: 4.244036809650765 and parameters: {'learning_rate': 0.09745136506898698, 'lambda_l1': 9.90345001570549, 'lambda_l2': 4.090540959640075, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:17,823]\u001b[0m Trial 85 finished with value: 4.289185536964374 and parameters: {'learning_rate': 0.04954022930832498, 'lambda_l1': 9.894097772950216, 'lambda_l2': 0.6530420808647599, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:21,896]\u001b[0m Trial 86 finished with value: 4.255323207560117 and parameters: {'learning_rate': 0.024900443387580826, 'lambda_l1': 6.625045718701713, 'lambda_l2': 2.4606318574490125, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:25,564]\u001b[0m Trial 87 finished with value: 4.221462707300311 and parameters: {'learning_rate': 0.04298480985514908, 'lambda_l1': 5.5468780910673114, 'lambda_l2': 2.870515206325782, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:28,173]\u001b[0m Trial 88 finished with value: 4.1876009005087536 and parameters: {'learning_rate': 0.036694010488103335, 'lambda_l1': 8.286569147270809, 'lambda_l2': 9.249669120282253, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:31,035]\u001b[0m Trial 89 finished with value: 4.1876006392024046 and parameters: {'learning_rate': 0.03550341757976376, 'lambda_l1': 8.149664795552809, 'lambda_l2': 9.85491427657806, 'bagging_freq': 7, 'min_child_samples': 91}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:34,411]\u001b[0m Trial 90 finished with value: 4.2778991390550205 and parameters: {'learning_rate': 0.03035907024133896, 'lambda_l1': 9.92011243422463, 'lambda_l2': 2.4942004180703115, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:37,420]\u001b[0m Trial 91 finished with value: 4.187600116589705 and parameters: {'learning_rate': 0.024108605291341536, 'lambda_l1': 6.897682653879821, 'lambda_l2': 0.583563599222323, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:41,213]\u001b[0m Trial 92 finished with value: 4.10858905987184 and parameters: {'learning_rate': 0.02797125265113029, 'lambda_l1': 3.790568966983716, 'lambda_l2': 3.7429618394661985, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:45,145]\u001b[0m Trial 93 finished with value: 4.074727775692983 and parameters: {'learning_rate': 0.01801345680571666, 'lambda_l1': 4.492916492384464, 'lambda_l2': 3.0446840807285107, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:47,927]\u001b[0m Trial 94 finished with value: 4.198888604949856 and parameters: {'learning_rate': 0.050736556291436884, 'lambda_l1': 9.425835997553468, 'lambda_l2': 6.33997698110663, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:50,385]\u001b[0m Trial 95 finished with value: 4.210175002859209 and parameters: {'learning_rate': 0.07532572132674885, 'lambda_l1': 6.995750605251763, 'lambda_l2': 9.679655666362615, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:54,309]\u001b[0m Trial 96 finished with value: 4.131164207447695 and parameters: {'learning_rate': 0.008016108040236627, 'lambda_l1': 2.927940321477248, 'lambda_l2': 1.5235470653537573, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:04:57,283]\u001b[0m Trial 97 finished with value: 4.198887559724456 and parameters: {'learning_rate': 0.06080766259806732, 'lambda_l1': 3.82808059775046, 'lambda_l2': 8.953858843928241, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:00,090]\u001b[0m Trial 98 finished with value: 4.187600377896055 and parameters: {'learning_rate': 0.028207533416892066, 'lambda_l1': 5.922304191696063, 'lambda_l2': 8.967611583276486, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:03,038]\u001b[0m Trial 99 finished with value: 4.3117609458465775 and parameters: {'learning_rate': 0.027893623993008442, 'lambda_l1': 4.554441499945828, 'lambda_l2': 4.017135359778851, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 2 with value: 4.029578003153976.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'learning_rate': 0.0793807787701838,\n",
       " 'lambda_l1': 5.2889492022400955,\n",
       " 'lambda_l2': 5.680445615258877,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 11,\n",
       " 'max_depth': 5,\n",
       " 'random_state': 0,\n",
       " 'num_boost_round': 10000,\n",
       " 'verbosity': -100}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lightgbm\n",
    "### \n",
    "\n",
    "# \n",
    "lgbm = models.Lgbm(config[\"model_params\"][\"Lgbm\"])\n",
    "optimized_params = beyesian_optimization(lgbm, X_train, y_train, {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'lambda_l1': [1e-8, 10.0],\n",
    "    'lambda_l2': [1e-8, 10.0],\n",
    "    'bagging_freq': [1, 7],\n",
    "    'min_child_samples': [5, 100],\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'max_depth': 5,\n",
    "    'random_state': 0,\n",
    "    'num_boost_round': 10000,\n",
    "    'verbosity': -100,\n",
    "}, n_trials)\n",
    "optimized_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'learning_rate': 0.0793807787701838, 'lambda_l1': 5.2889492022400955, 'lambda_l2': 5.680445615258877, 'bagging_freq': 7, 'min_child_samples': 11, 'max_depth': 5, 'random_state': 0, 'num_boost_round': 10000, 'verbosity': -100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8785294117647059\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)\n",
    "print(cross_validation_score(models.Lgbm(optimized_params), X_train, y_train))\n",
    "with open('./config/Lgbm-depth-5.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 09:05:18,823]\u001b[0m A new study created in memory with name: no-name-0ba90152-42a2-4e7a-a3c4-a7e9156287a2\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:22,318]\u001b[0m Trial 0 finished with value: 4.255323468866467 and parameters: {'learning_rate': 0.055332536888805156, 'lambda_l1': 7.151893666572301, 'lambda_l2': 6.0276337646888045, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 0 with value: 4.255323468866467.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:25,608]\u001b[0m Trial 1 finished with value: 4.153740138942597 and parameters: {'learning_rate': 0.06494351719359896, 'lambda_l1': 4.375872118251053, 'lambda_l2': 8.917730008903067, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 1 with value: 4.153740138942597.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:29,140]\u001b[0m Trial 2 finished with value: 4.1198767643129415 and parameters: {'learning_rate': 0.0793807787701838, 'lambda_l1': 5.2889492022400955, 'lambda_l2': 5.680445615258877, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:48,981]\u001b[0m Trial 3 finished with value: 4.898701456194933 and parameters: {'learning_rate': 0.00962580067045253, 'lambda_l1': 0.2021839842010732, 'lambda_l2': 8.32619845715318, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:51,750]\u001b[0m Trial 4 finished with value: 4.221464013832059 and parameters: {'learning_rate': 0.09788321588104364, 'lambda_l1': 7.991585644175649, 'lambda_l2': 4.6147936279145245, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:55,497]\u001b[0m Trial 5 finished with value: 4.4133476727529946 and parameters: {'learning_rate': 0.06435218111142486, 'lambda_l1': 1.433532882656931, 'lambda_l2': 9.44668917104915, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:05:58,735]\u001b[0m Trial 6 finished with value: 4.029577741847626 and parameters: {'learning_rate': 0.027191005598358072, 'lambda_l1': 7.742336896599829, 'lambda_l2': 4.561503327603981, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:05,689]\u001b[0m Trial 7 finished with value: 4.198888343643506 and parameters: {'learning_rate': 0.062145914210511834, 'lambda_l1': 6.120957231103256, 'lambda_l2': 6.1693399725782285, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:09,432]\u001b[0m Trial 8 finished with value: 4.198889650175254 and parameters: {'learning_rate': 0.036591282156804815, 'lambda_l1': 4.370319543623094, 'lambda_l2': 6.976311962296336, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:13,073]\u001b[0m Trial 9 finished with value: 4.368198684133036 and parameters: {'learning_rate': 0.06739314909219779, 'lambda_l1': 2.103825618634583, 'lambda_l2': 1.2892629852592699, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:16,582]\u001b[0m Trial 10 finished with value: 4.165027059464649 and parameters: {'learning_rate': 0.05744948027137009, 'lambda_l1': 4.386015140237188, 'lambda_l2': 9.883738380708524, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:19,715]\u001b[0m Trial 11 finished with value: 4.1876006392024046 and parameters: {'learning_rate': 0.01696964227061463, 'lambda_l1': 6.531083258122901, 'lambda_l2': 2.5329160328649047, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:26,154]\u001b[0m Trial 12 finished with value: 4.729391638318103 and parameters: {'learning_rate': 0.016737988780906453, 'lambda_l1': 1.1037514205392998, 'lambda_l2': 6.563295898089438, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:29,832]\u001b[0m Trial 13 finished with value: 4.176313457374002 and parameters: {'learning_rate': 0.03750379189543545, 'lambda_l1': 8.209932300269418, 'lambda_l2': 0.9710127669595999, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:33,832]\u001b[0m Trial 14 finished with value: 4.1763155478247995 and parameters: {'learning_rate': 0.09766948703632619, 'lambda_l1': 4.686512021790503, 'lambda_l2': 9.767610882135761, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:42,103]\u001b[0m Trial 15 finished with value: 4.266612218532968 and parameters: {'learning_rate': 0.004879591433177747, 'lambda_l1': 2.828069632936026, 'lambda_l2': 1.2019656209297234, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:46,257]\u001b[0m Trial 16 finished with value: 4.221464013832059 and parameters: {'learning_rate': 0.03248033476000363, 'lambda_l1': 4.14262995100407, 'lambda_l2': 0.6414749728463687, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:49,689]\u001b[0m Trial 17 finished with value: 4.176315025212101 and parameters: {'learning_rate': 0.0272735596030051, 'lambda_l1': 5.2324805394345155, 'lambda_l2': 0.9394051166450116, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:53,357]\u001b[0m Trial 18 finished with value: 4.22146218468761 and parameters: {'learning_rate': 0.032538326292681045, 'lambda_l1': 6.674103802962713, 'lambda_l2': 1.3179786327259428, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:56,842]\u001b[0m Trial 19 finished with value: 4.176313196067652 and parameters: {'learning_rate': 0.01913594483870457, 'lambda_l1': 5.8651293522357015, 'lambda_l2': 0.20107547167386003, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:06:59,806]\u001b[0m Trial 20 finished with value: 4.356911502304634 and parameters: {'learning_rate': 0.06810383714282678, 'lambda_l1': 2.7000797392215685, 'lambda_l2': 7.351940223874008, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:02,915]\u001b[0m Trial 21 finished with value: 4.1650273207709985 and parameters: {'learning_rate': 0.058039576107365855, 'lambda_l1': 5.92041931679797, 'lambda_l2': 5.7225190621862145, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:05,230]\u001b[0m Trial 22 finished with value: 4.22146296860666 and parameters: {'learning_rate': 0.04526541248314511, 'lambda_l1': 8.464086726247192, 'lambda_l2': 6.994792756180249, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:07,513]\u001b[0m Trial 23 finished with value: 4.22146322991301 and parameters: {'learning_rate': 0.040254068343851486, 'lambda_l1': 8.811031972300585, 'lambda_l2': 5.8127287305458575, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:10,182]\u001b[0m Trial 24 finished with value: 4.232750934354112 and parameters: {'learning_rate': 0.07280017370214442, 'lambda_l1': 5.013243824253778, 'lambda_l2': 9.560836347671403, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:16,227]\u001b[0m Trial 25 finished with value: 5.0567209565671645 and parameters: {'learning_rate': 0.061032928198664516, 'lambda_l1': 0.19193199290140325, 'lambda_l2': 3.0157481737297447, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:19,140]\u001b[0m Trial 26 finished with value: 4.198890172787954 and parameters: {'learning_rate': 0.06218352747088532, 'lambda_l1': 4.287687015169974, 'lambda_l2': 1.3547406508697615, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:22,363]\u001b[0m Trial 27 finished with value: 4.198888082337156 and parameters: {'learning_rate': 0.05949640336356915, 'lambda_l1': 5.743252492752535, 'lambda_l2': 6.532008202039328, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:26,471]\u001b[0m Trial 28 finished with value: 4.165027582077348 and parameters: {'learning_rate': 0.08975811298925525, 'lambda_l1': 3.675618706803346, 'lambda_l2': 4.358649258297619, 'bagging_freq': 7, 'min_child_samples': 82}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:30,551]\u001b[0m Trial 29 finished with value: 4.695528786301147 and parameters: {'learning_rate': 0.07068496977049626, 'lambda_l1': 1.0022688821207422, 'lambda_l2': 9.19482613825191, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:33,909]\u001b[0m Trial 30 finished with value: 4.210176048084608 and parameters: {'learning_rate': 0.01579538216114138, 'lambda_l1': 8.681260575000882, 'lambda_l2': 1.6249293551388186, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:36,468]\u001b[0m Trial 31 finished with value: 4.22146270730031 and parameters: {'learning_rate': 0.08495281470290121, 'lambda_l1': 8.073189589176918, 'lambda_l2': 5.691007390454925, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:39,144]\u001b[0m Trial 32 finished with value: 4.198889650175254 and parameters: {'learning_rate': 0.07004544854131181, 'lambda_l1': 4.535426832245261, 'lambda_l2': 7.220555997482923, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:45,307]\u001b[0m Trial 33 finished with value: 5.079296365449368 and parameters: {'learning_rate': 0.08572453089686849, 'lambda_l1': 0.11714085173287886, 'lambda_l2': 3.599780651183858, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:51,551]\u001b[0m Trial 34 finished with value: 4.774538275180913 and parameters: {'learning_rate': 0.0525826240142088, 'lambda_l1': 0.5433798928491564, 'lambda_l2': 1.9999652569640354, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:07:57,536]\u001b[0m Trial 35 finished with value: 4.119877025619292 and parameters: {'learning_rate': 0.023168544117977634, 'lambda_l1': 3.4535168135155097, 'lambda_l2': 9.280812935375096, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:03,128]\u001b[0m Trial 36 finished with value: 4.165026798158299 and parameters: {'learning_rate': 0.017304721493293363, 'lambda_l1': 6.214784018782851, 'lambda_l2': 5.77228589026939, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:07,154]\u001b[0m Trial 37 finished with value: 4.131163946141344 and parameters: {'learning_rate': 0.061782629640623705, 'lambda_l1': 5.356328034893255, 'lambda_l2': 5.89909976764661, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:10,771]\u001b[0m Trial 38 finished with value: 4.537506672865419 and parameters: {'learning_rate': 0.040423885159393096, 'lambda_l1': 2.0984374976527835, 'lambda_l2': 1.8619300669414314, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:15,115]\u001b[0m Trial 39 finished with value: 4.458497183985652 and parameters: {'learning_rate': 0.04955542205313914, 'lambda_l1': 2.274146287459086, 'lambda_l2': 2.5435648251603644, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:18,603]\u001b[0m Trial 40 finished with value: 4.1198767643129415 and parameters: {'learning_rate': 0.031867792317416155, 'lambda_l1': 6.963434891191159, 'lambda_l2': 3.7775183991472905, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:23,665]\u001b[0m Trial 41 finished with value: 4.142451911888795 and parameters: {'learning_rate': 0.00765771351486161, 'lambda_l1': 6.793927738191745, 'lambda_l2': 4.536968451023484, 'bagging_freq': 4, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:28,127]\u001b[0m Trial 42 finished with value: 4.2440370709571145 and parameters: {'learning_rate': 0.09904355579227374, 'lambda_l1': 2.168969851815769, 'lambda_l2': 6.630782034370226, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:31,184]\u001b[0m Trial 43 finished with value: 4.210175786778257 and parameters: {'learning_rate': 0.076079486729778, 'lambda_l1': 3.2001715150245067, 'lambda_l2': 3.8346389478843403, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:33,635]\u001b[0m Trial 44 finished with value: 4.266613002452017 and parameters: {'learning_rate': 0.06326920251552372, 'lambda_l1': 8.726506555747447, 'lambda_l2': 2.735420355420937, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:36,073]\u001b[0m Trial 45 finished with value: 4.1876006392024046 and parameters: {'learning_rate': 0.09532637404022251, 'lambda_l1': 6.874882767003269, 'lambda_l2': 2.1550767789805074, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:39,181]\u001b[0m Trial 46 finished with value: 4.413347150140295 and parameters: {'learning_rate': 0.02614022261690756, 'lambda_l1': 2.1331197815416996, 'lambda_l2': 5.182007144124625, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:41,851]\u001b[0m Trial 47 finished with value: 4.232750934354112 and parameters: {'learning_rate': 0.043043861406399125, 'lambda_l1': 3.741699809600555, 'lambda_l2': 4.6357542490123524, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:44,926]\u001b[0m Trial 48 finished with value: 4.650379797681189 and parameters: {'learning_rate': 0.08652170498639991, 'lambda_l1': 1.175318568445012, 'lambda_l2': 5.17379107636735, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:47,575]\u001b[0m Trial 49 finished with value: 4.198888866256206 and parameters: {'learning_rate': 0.04020991057792209, 'lambda_l1': 5.654213122930876, 'lambda_l2': 1.8327983703079875, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:50,164]\u001b[0m Trial 50 finished with value: 4.153739355023547 and parameters: {'learning_rate': 0.03620566104714561, 'lambda_l1': 9.404319453123811, 'lambda_l2': 7.653252540416399, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:08:56,049]\u001b[0m Trial 51 finished with value: 4.10858958248454 and parameters: {'learning_rate': 0.009258821108759838, 'lambda_l1': 5.52192470370214, 'lambda_l2': 5.844760693712927, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:01,257]\u001b[0m Trial 52 finished with value: 4.6278038661862855 and parameters: {'learning_rate': 0.024842049211629236, 'lambda_l1': 1.0029394316520386, 'lambda_l2': 0.16429630575044574, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:03,915]\u001b[0m Trial 53 finished with value: 4.255325820623614 and parameters: {'learning_rate': 0.07873013829029064, 'lambda_l1': 2.8173010647221894, 'lambda_l2': 5.864101665999165, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:06,652]\u001b[0m Trial 54 finished with value: 4.300475070549924 and parameters: {'learning_rate': 0.09777201883470024, 'lambda_l1': 8.765052454400855, 'lambda_l2': 3.3815895249868664, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:09,309]\u001b[0m Trial 55 finished with value: 4.119877548231991 and parameters: {'learning_rate': 0.09498256341915247, 'lambda_l1': 9.413777047651209, 'lambda_l2': 7.9920258755318905, 'bagging_freq': 5, 'min_child_samples': 88}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:11,946]\u001b[0m Trial 56 finished with value: 4.345623797863532 and parameters: {'learning_rate': 0.03000900816627188, 'lambda_l1': 8.489435554639746, 'lambda_l2': 6.178766922996471, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:14,518]\u001b[0m Trial 57 finished with value: 4.289188150027871 and parameters: {'learning_rate': 0.01566594523386834, 'lambda_l1': 9.818293898364239, 'lambda_l2': 4.783703075616177, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:18,221]\u001b[0m Trial 58 finished with value: 4.5036459112992615 and parameters: {'learning_rate': 0.03748987600683214, 'lambda_l1': 1.3690027254869863, 'lambda_l2': 8.221177333721277, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:26,261]\u001b[0m Trial 59 finished with value: 4.66166776342864 and parameters: {'learning_rate': 0.02320738586849919, 'lambda_l1': 0.9784448539618956, 'lambda_l2': 8.621915175594918, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:28,621]\u001b[0m Trial 60 finished with value: 4.334334786890682 and parameters: {'learning_rate': 0.09074899442289672, 'lambda_l1': 7.740473329245914, 'lambda_l2': 3.331451526954967, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:31,782]\u001b[0m Trial 61 finished with value: 4.458495877453903 and parameters: {'learning_rate': 0.023991180074923332, 'lambda_l1': 1.3248763562549533, 'lambda_l2': 0.5342718273339808, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:34,704]\u001b[0m Trial 62 finished with value: 4.593944149845528 and parameters: {'learning_rate': 0.07728749410177485, 'lambda_l1': 1.469466462534284, 'lambda_l2': 0.7952208350723367, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:37,708]\u001b[0m Trial 63 finished with value: 4.1988891275625555 and parameters: {'learning_rate': 0.025291353775431635, 'lambda_l1': 4.205394672595589, 'lambda_l2': 5.573687917665481, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:41,076]\u001b[0m Trial 64 finished with value: 4.593946240296326 and parameters: {'learning_rate': 0.02776246261863275, 'lambda_l1': 1.314828001596448, 'lambda_l2': 0.5537432136582362, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:43,966]\u001b[0m Trial 65 finished with value: 4.289185536964374 and parameters: {'learning_rate': 0.04615791611324749, 'lambda_l1': 6.832813358643991, 'lambda_l2': 6.956254459432317, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:46,589]\u001b[0m Trial 66 finished with value: 4.176313457374002 and parameters: {'learning_rate': 0.018933945211953403, 'lambda_l1': 7.885455125179731, 'lambda_l2': 0.5684807737639223, 'bagging_freq': 5, 'min_child_samples': 79}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:49,191]\u001b[0m Trial 67 finished with value: 4.368198161520336 and parameters: {'learning_rate': 0.07796334862302656, 'lambda_l1': 2.5942256508593236, 'lambda_l2': 3.7381313855874825, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:53,342]\u001b[0m Trial 68 finished with value: 4.424634331968697 and parameters: {'learning_rate': 0.03771442712257098, 'lambda_l1': 1.9705428098858533, 'lambda_l2': 4.5985588429615145, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:09:56,747]\u001b[0m Trial 69 finished with value: 4.187602729653202 and parameters: {'learning_rate': 0.00861868825167664, 'lambda_l1': 5.188351493126908, 'lambda_l2': 3.0681010023838597, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:01,871]\u001b[0m Trial 70 finished with value: 4.943848876976793 and parameters: {'learning_rate': 0.06491145420114439, 'lambda_l1': 0.35362436720128476, 'lambda_l2': 4.304024400776587, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:04,394]\u001b[0m Trial 71 finished with value: 4.356909934466535 and parameters: {'learning_rate': 0.06845785854977995, 'lambda_l1': 2.7759609845416997, 'lambda_l2': 1.2886056633745961, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:07,135]\u001b[0m Trial 72 finished with value: 4.210175002859209 and parameters: {'learning_rate': 0.01952595828333363, 'lambda_l1': 9.039839550242531, 'lambda_l2': 5.438059505335204, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:09,603]\u001b[0m Trial 73 finished with value: 4.176314241293051 and parameters: {'learning_rate': 0.046401792215090006, 'lambda_l1': 7.2416763688737555, 'lambda_l2': 3.9902532230407664, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:12,150]\u001b[0m Trial 74 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.07026258337080116, 'lambda_l1': 3.2772040222939847, 'lambda_l2': 7.567786429801105, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:14,682]\u001b[0m Trial 75 finished with value: 4.2214632299130095 and parameters: {'learning_rate': 0.016893343426040385, 'lambda_l1': 7.963914747209402, 'lambda_l2': 9.591666030760559, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:17,327]\u001b[0m Trial 76 finished with value: 4.142454786258643 and parameters: {'learning_rate': 0.0859145417751619, 'lambda_l1': 4.5722345389663355, 'lambda_l2': 9.518744768808617, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:19,971]\u001b[0m Trial 77 finished with value: 4.323049434206728 and parameters: {'learning_rate': 0.09097552812286111, 'lambda_l1': 8.15523818953045, 'lambda_l2': 1.5941446428954145, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:24,254]\u001b[0m Trial 78 finished with value: 4.142451650582446 and parameters: {'learning_rate': 0.007208582250311225, 'lambda_l1': 4.2403225246580964, 'lambda_l2': 2.586840676307236, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:26,719]\u001b[0m Trial 79 finished with value: 4.198888343643506 and parameters: {'learning_rate': 0.09593928946448389, 'lambda_l1': 3.5536884911656075, 'lambda_l2': 3.5670689104583597, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:29,079]\u001b[0m Trial 80 finished with value: 4.255325559317265 and parameters: {'learning_rate': 0.040724690579557264, 'lambda_l1': 9.292914173734225, 'lambda_l2': 0.9961493112165639, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:31,723]\u001b[0m Trial 81 finished with value: 4.097303184575187 and parameters: {'learning_rate': 0.04596207729384763, 'lambda_l1': 3.2670088244155915, 'lambda_l2': 2.327441300463127, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:38,614]\u001b[0m Trial 82 finished with value: 4.142452957114195 and parameters: {'learning_rate': 0.0025450003802359933, 'lambda_l1': 4.2879572306944205, 'lambda_l2': 0.6807407490664613, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:41,843]\u001b[0m Trial 83 finished with value: 4.616517468276933 and parameters: {'learning_rate': 0.026065928178562344, 'lambda_l1': 1.310552320842025, 'lambda_l2': 0.12036223885618046, 'bagging_freq': 1, 'min_child_samples': 64}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:44,482]\u001b[0m Trial 84 finished with value: 4.300473764018174 and parameters: {'learning_rate': 0.09745136506898698, 'lambda_l1': 9.90345001570549, 'lambda_l2': 4.090540959640075, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:46,829]\u001b[0m Trial 85 finished with value: 4.289186843496123 and parameters: {'learning_rate': 0.04954022930832498, 'lambda_l1': 9.894097772950216, 'lambda_l2': 0.6530420808647599, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:49,420]\u001b[0m Trial 86 finished with value: 4.289186582189772 and parameters: {'learning_rate': 0.024900443387580826, 'lambda_l1': 6.625045718701713, 'lambda_l2': 2.4606318574490125, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:51,975]\u001b[0m Trial 87 finished with value: 4.232750150435062 and parameters: {'learning_rate': 0.04298480985514908, 'lambda_l1': 5.5468780910673114, 'lambda_l2': 2.870515206325782, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:54,429]\u001b[0m Trial 88 finished with value: 4.210176570697307 and parameters: {'learning_rate': 0.036694010488103335, 'lambda_l1': 8.286569147270809, 'lambda_l2': 9.249669120282253, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:56,970]\u001b[0m Trial 89 finished with value: 4.266611695920268 and parameters: {'learning_rate': 0.03550341757976376, 'lambda_l1': 8.149664795552809, 'lambda_l2': 9.85491427657806, 'bagging_freq': 7, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:10:59,850]\u001b[0m Trial 90 finished with value: 4.210176832003657 and parameters: {'learning_rate': 0.03035907024133896, 'lambda_l1': 9.92011243422463, 'lambda_l2': 2.4942004180703115, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:02,431]\u001b[0m Trial 91 finished with value: 4.1876009005087536 and parameters: {'learning_rate': 0.024108605291341536, 'lambda_l1': 6.897682653879821, 'lambda_l2': 0.583563599222323, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:05,258]\u001b[0m Trial 92 finished with value: 4.131165252673093 and parameters: {'learning_rate': 0.02797125265113029, 'lambda_l1': 3.790568966983716, 'lambda_l2': 3.7429618394661985, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:08,307]\u001b[0m Trial 93 finished with value: 4.153740138942597 and parameters: {'learning_rate': 0.01801345680571666, 'lambda_l1': 4.492916492384464, 'lambda_l2': 3.0446840807285107, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:10,628]\u001b[0m Trial 94 finished with value: 4.1988893888689045 and parameters: {'learning_rate': 0.050736556291436884, 'lambda_l1': 9.425835997553468, 'lambda_l2': 6.33997698110663, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:12,946]\u001b[0m Trial 95 finished with value: 4.232749366516013 and parameters: {'learning_rate': 0.07532572132674885, 'lambda_l1': 6.995750605251763, 'lambda_l2': 9.679655666362615, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:17,023]\u001b[0m Trial 96 finished with value: 4.27789992297407 and parameters: {'learning_rate': 0.008016108040236627, 'lambda_l1': 2.927940321477248, 'lambda_l2': 1.5235470653537573, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:19,677]\u001b[0m Trial 97 finished with value: 4.1763155478247995 and parameters: {'learning_rate': 0.06080766259806732, 'lambda_l1': 3.82808059775046, 'lambda_l2': 8.953858843928241, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:22,261]\u001b[0m Trial 98 finished with value: 4.119877025619292 and parameters: {'learning_rate': 0.028207533416892066, 'lambda_l1': 5.922304191696063, 'lambda_l2': 8.967611583276486, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:25,229]\u001b[0m Trial 99 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.027893623993008442, 'lambda_l1': 4.554441499945828, 'lambda_l2': 4.017135359778851, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'learning_rate': 0.027191005598358072,\n",
       " 'lambda_l1': 7.742336896599829,\n",
       " 'lambda_l2': 4.561503327603981,\n",
       " 'bagging_freq': 4,\n",
       " 'min_child_samples': 6,\n",
       " 'max_depth': 15,\n",
       " 'random_state': 0,\n",
       " 'num_boost_round': 10000,\n",
       " 'verbosity': -100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lightgbm\n",
    "### \n",
    "\n",
    "# \n",
    "lgbm = models.Lgbm(config[\"model_params\"][\"Lgbm\"])\n",
    "optimized_params = beyesian_optimization(lgbm, X_train, y_train, {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'lambda_l1': [1e-8, 10.0],\n",
    "    'lambda_l2': [1e-8, 10.0],\n",
    "    'bagging_freq': [1, 7],\n",
    "    'min_child_samples': [5, 100],\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'max_depth': 15,\n",
    "    'random_state': 0,\n",
    "    'num_boost_round': 10000,\n",
    "    'verbosity': -100,\n",
    "}, n_trials)\n",
    "optimized_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'learning_rate': 0.027191005598358072, 'lambda_l1': 7.742336896599829, 'lambda_l2': 4.561503327603981, 'bagging_freq': 4, 'min_child_samples': 6, 'max_depth': 15, 'random_state': 0, 'num_boost_round': 10000, 'verbosity': -100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795098039215686\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)\n",
    "print(cross_validation_score(models.Lgbm(optimized_params), X_train, y_train))\n",
    "with open('./config/Lgbm-depth-15.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 09:11:39,545]\u001b[0m A new study created in memory with name: no-name-86b51d56-0dfc-4d13-a0fc-87c6e4a6fe19\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:42,254]\u001b[0m Trial 0 finished with value: 4.255323468866467 and parameters: {'learning_rate': 0.055332536888805156, 'lambda_l1': 7.151893666572301, 'lambda_l2': 6.0276337646888045, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 0 with value: 4.255323468866467.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:44,918]\u001b[0m Trial 1 finished with value: 4.153740138942597 and parameters: {'learning_rate': 0.06494351719359896, 'lambda_l1': 4.375872118251053, 'lambda_l2': 8.917730008903067, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 1 with value: 4.153740138942597.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:11:47,381]\u001b[0m Trial 2 finished with value: 4.1198767643129415 and parameters: {'learning_rate': 0.0793807787701838, 'lambda_l1': 5.2889492022400955, 'lambda_l2': 5.680445615258877, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:00,717]\u001b[0m Trial 3 finished with value: 4.808403478955016 and parameters: {'learning_rate': 0.00962580067045253, 'lambda_l1': 0.2021839842010732, 'lambda_l2': 8.32619845715318, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:05,244]\u001b[0m Trial 4 finished with value: 4.221464013832059 and parameters: {'learning_rate': 0.09788321588104364, 'lambda_l1': 7.991585644175649, 'lambda_l2': 4.6147936279145245, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:10,635]\u001b[0m Trial 5 finished with value: 4.492358729470859 and parameters: {'learning_rate': 0.06435218111142486, 'lambda_l1': 1.433532882656931, 'lambda_l2': 9.44668917104915, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 2 with value: 4.1198767643129415.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:15,333]\u001b[0m Trial 6 finished with value: 4.029577741847626 and parameters: {'learning_rate': 0.027191005598358072, 'lambda_l1': 7.742336896599829, 'lambda_l2': 4.561503327603981, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:20,014]\u001b[0m Trial 7 finished with value: 4.198888343643506 and parameters: {'learning_rate': 0.062145914210511834, 'lambda_l1': 6.120957231103256, 'lambda_l2': 6.1693399725782285, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:24,306]\u001b[0m Trial 8 finished with value: 4.198889650175254 and parameters: {'learning_rate': 0.036591282156804815, 'lambda_l1': 4.370319543623094, 'lambda_l2': 6.976311962296336, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:29,912]\u001b[0m Trial 9 finished with value: 4.402060229618243 and parameters: {'learning_rate': 0.06739314909219779, 'lambda_l1': 2.103825618634583, 'lambda_l2': 1.2892629852592699, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:35,814]\u001b[0m Trial 10 finished with value: 4.10859010509724 and parameters: {'learning_rate': 0.05744948027137009, 'lambda_l1': 4.386015140237188, 'lambda_l2': 9.883738380708524, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:41,452]\u001b[0m Trial 11 finished with value: 4.1876006392024046 and parameters: {'learning_rate': 0.01696964227061463, 'lambda_l1': 6.531083258122901, 'lambda_l2': 2.5329160328649047, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:50,657]\u001b[0m Trial 12 finished with value: 4.639092877159136 and parameters: {'learning_rate': 0.016737988780906453, 'lambda_l1': 1.1037514205392998, 'lambda_l2': 6.563295898089438, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:12:55,716]\u001b[0m Trial 13 finished with value: 4.176313457374002 and parameters: {'learning_rate': 0.03750379189543545, 'lambda_l1': 8.209932300269418, 'lambda_l2': 0.9710127669595999, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:00,155]\u001b[0m Trial 14 finished with value: 4.1763155478247995 and parameters: {'learning_rate': 0.09766948703632619, 'lambda_l1': 4.686512021790503, 'lambda_l2': 9.767610882135761, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:09,730]\u001b[0m Trial 15 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.004879591433177747, 'lambda_l1': 2.828069632936026, 'lambda_l2': 1.2019656209297234, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:14,994]\u001b[0m Trial 16 finished with value: 4.1988893888689045 and parameters: {'learning_rate': 0.03248033476000363, 'lambda_l1': 4.14262995100407, 'lambda_l2': 0.6414749728463687, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:19,686]\u001b[0m Trial 17 finished with value: 4.176315025212101 and parameters: {'learning_rate': 0.0272735596030051, 'lambda_l1': 5.2324805394345155, 'lambda_l2': 0.9394051166450116, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:23,925]\u001b[0m Trial 18 finished with value: 4.22146218468761 and parameters: {'learning_rate': 0.032538326292681045, 'lambda_l1': 6.674103802962713, 'lambda_l2': 1.3179786327259428, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:28,390]\u001b[0m Trial 19 finished with value: 4.176313196067652 and parameters: {'learning_rate': 0.01913594483870457, 'lambda_l1': 5.8651293522357015, 'lambda_l2': 0.20107547167386003, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:32,974]\u001b[0m Trial 20 finished with value: 4.311762252378325 and parameters: {'learning_rate': 0.06810383714282678, 'lambda_l1': 2.7000797392215685, 'lambda_l2': 7.351940223874008, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:37,581]\u001b[0m Trial 21 finished with value: 4.1650273207709985 and parameters: {'learning_rate': 0.058039576107365855, 'lambda_l1': 5.92041931679797, 'lambda_l2': 5.7225190621862145, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:41,489]\u001b[0m Trial 22 finished with value: 4.22146296860666 and parameters: {'learning_rate': 0.04526541248314511, 'lambda_l1': 8.464086726247192, 'lambda_l2': 6.994792756180249, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:45,442]\u001b[0m Trial 23 finished with value: 4.22146322991301 and parameters: {'learning_rate': 0.040254068343851486, 'lambda_l1': 8.811031972300585, 'lambda_l2': 5.8127287305458575, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:13:50,541]\u001b[0m Trial 24 finished with value: 4.232750934354112 and parameters: {'learning_rate': 0.07280017370214442, 'lambda_l1': 5.013243824253778, 'lambda_l2': 9.560836347671403, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:00,638]\u001b[0m Trial 25 finished with value: 4.943848354364094 and parameters: {'learning_rate': 0.061032928198664516, 'lambda_l1': 0.19193199290140325, 'lambda_l2': 3.0157481737297447, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:05,742]\u001b[0m Trial 26 finished with value: 4.198890172787954 and parameters: {'learning_rate': 0.06218352747088532, 'lambda_l1': 4.287687015169974, 'lambda_l2': 1.3547406508697615, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:09,763]\u001b[0m Trial 27 finished with value: 4.198888082337156 and parameters: {'learning_rate': 0.05949640336356915, 'lambda_l1': 5.743252492752535, 'lambda_l2': 6.532008202039328, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:14,770]\u001b[0m Trial 28 finished with value: 4.165027582077348 and parameters: {'learning_rate': 0.08975811298925525, 'lambda_l1': 3.675618706803346, 'lambda_l2': 4.358649258297619, 'bagging_freq': 7, 'min_child_samples': 82}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:22,374]\u001b[0m Trial 29 finished with value: 4.729390331786354 and parameters: {'learning_rate': 0.07068496977049626, 'lambda_l1': 1.0022688821207422, 'lambda_l2': 9.19482613825191, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:28,011]\u001b[0m Trial 30 finished with value: 4.210176048084608 and parameters: {'learning_rate': 0.01579538216114138, 'lambda_l1': 8.681260575000882, 'lambda_l2': 1.6249293551388186, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:33,679]\u001b[0m Trial 31 finished with value: 4.22146270730031 and parameters: {'learning_rate': 0.08495281470290121, 'lambda_l1': 8.073189589176918, 'lambda_l2': 5.691007390454925, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:39,130]\u001b[0m Trial 32 finished with value: 4.198889650175254 and parameters: {'learning_rate': 0.07004544854131181, 'lambda_l1': 4.535426832245261, 'lambda_l2': 7.220555997482923, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:14:52,828]\u001b[0m Trial 33 finished with value: 4.955135797498846 and parameters: {'learning_rate': 0.08572453089686849, 'lambda_l1': 0.11714085173287886, 'lambda_l2': 3.599780651183858, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:00,688]\u001b[0m Trial 34 finished with value: 4.763251877271561 and parameters: {'learning_rate': 0.0525826240142088, 'lambda_l1': 0.5433798928491564, 'lambda_l2': 1.9999652569640354, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:07,265]\u001b[0m Trial 35 finished with value: 4.119877025619292 and parameters: {'learning_rate': 0.023168544117977634, 'lambda_l1': 3.4535168135155097, 'lambda_l2': 9.280812935375096, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:12,184]\u001b[0m Trial 36 finished with value: 4.165026798158299 and parameters: {'learning_rate': 0.017304721493293363, 'lambda_l1': 6.214784018782851, 'lambda_l2': 5.77228589026939, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:18,116]\u001b[0m Trial 37 finished with value: 4.131163946141344 and parameters: {'learning_rate': 0.061782629640623705, 'lambda_l1': 5.356328034893255, 'lambda_l2': 5.89909976764661, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:24,518]\u001b[0m Trial 38 finished with value: 4.5375079793971675 and parameters: {'learning_rate': 0.040423885159393096, 'lambda_l1': 2.0984374976527835, 'lambda_l2': 1.8619300669414314, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:29,230]\u001b[0m Trial 39 finished with value: 4.435923865554247 and parameters: {'learning_rate': 0.04955542205313914, 'lambda_l1': 2.274146287459086, 'lambda_l2': 2.5435648251603644, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:34,857]\u001b[0m Trial 40 finished with value: 4.1198767643129415 and parameters: {'learning_rate': 0.031867792317416155, 'lambda_l1': 6.963434891191159, 'lambda_l2': 3.7775183991472905, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:40,614]\u001b[0m Trial 41 finished with value: 4.142451911888795 and parameters: {'learning_rate': 0.00765771351486161, 'lambda_l1': 6.793927738191745, 'lambda_l2': 4.536968451023484, 'bagging_freq': 4, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:44,934]\u001b[0m Trial 42 finished with value: 4.1876009005087536 and parameters: {'learning_rate': 0.09904355579227374, 'lambda_l1': 2.168969851815769, 'lambda_l2': 6.630782034370226, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:49,298]\u001b[0m Trial 43 finished with value: 4.323048911594028 and parameters: {'learning_rate': 0.076079486729778, 'lambda_l1': 3.2001715150245067, 'lambda_l2': 3.8346389478843403, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:53,214]\u001b[0m Trial 44 finished with value: 4.266613002452017 and parameters: {'learning_rate': 0.06326920251552372, 'lambda_l1': 8.726506555747447, 'lambda_l2': 2.735420355420937, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:15:57,145]\u001b[0m Trial 45 finished with value: 4.1876006392024046 and parameters: {'learning_rate': 0.09532637404022251, 'lambda_l1': 6.874882767003269, 'lambda_l2': 2.1550767789805074, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:02,934]\u001b[0m Trial 46 finished with value: 4.368197900213986 and parameters: {'learning_rate': 0.02614022261690756, 'lambda_l1': 2.1331197815416996, 'lambda_l2': 5.182007144124625, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:08,512]\u001b[0m Trial 47 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.043043861406399125, 'lambda_l1': 3.741699809600555, 'lambda_l2': 4.6357542490123524, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:14,153]\u001b[0m Trial 48 finished with value: 4.7068162294358995 and parameters: {'learning_rate': 0.08652170498639991, 'lambda_l1': 1.175318568445012, 'lambda_l2': 5.17379107636735, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:19,252]\u001b[0m Trial 49 finished with value: 4.198888866256206 and parameters: {'learning_rate': 0.04020991057792209, 'lambda_l1': 5.654213122930876, 'lambda_l2': 1.8327983703079875, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:23,377]\u001b[0m Trial 50 finished with value: 4.153739355023547 and parameters: {'learning_rate': 0.03620566104714561, 'lambda_l1': 9.404319453123811, 'lambda_l2': 7.653252540416399, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:29,681]\u001b[0m Trial 51 finished with value: 4.10858984379089 and parameters: {'learning_rate': 0.009258821108759838, 'lambda_l1': 5.52192470370214, 'lambda_l2': 5.844760693712927, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:36,590]\u001b[0m Trial 52 finished with value: 4.661666718203241 and parameters: {'learning_rate': 0.024842049211629236, 'lambda_l1': 1.0029394316520386, 'lambda_l2': 0.16429630575044574, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:41,067]\u001b[0m Trial 53 finished with value: 4.334336877341479 and parameters: {'learning_rate': 0.07873013829029064, 'lambda_l1': 2.8173010647221894, 'lambda_l2': 5.864101665999165, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:45,225]\u001b[0m Trial 54 finished with value: 4.300475070549924 and parameters: {'learning_rate': 0.09777201883470024, 'lambda_l1': 8.765052454400855, 'lambda_l2': 3.3815895249868664, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:49,205]\u001b[0m Trial 55 finished with value: 4.119877548231991 and parameters: {'learning_rate': 0.09498256341915247, 'lambda_l1': 9.413777047651209, 'lambda_l2': 7.9920258755318905, 'bagging_freq': 5, 'min_child_samples': 88}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:53,189]\u001b[0m Trial 56 finished with value: 4.345623797863532 and parameters: {'learning_rate': 0.03000900816627188, 'lambda_l1': 8.489435554639746, 'lambda_l2': 6.178766922996471, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:16:57,422]\u001b[0m Trial 57 finished with value: 4.289188150027871 and parameters: {'learning_rate': 0.01566594523386834, 'lambda_l1': 9.818293898364239, 'lambda_l2': 4.783703075616177, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:03,021]\u001b[0m Trial 58 finished with value: 4.503645388686562 and parameters: {'learning_rate': 0.03748987600683214, 'lambda_l1': 1.3690027254869863, 'lambda_l2': 8.221177333721277, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:14,666]\u001b[0m Trial 59 finished with value: 4.593944672458227 and parameters: {'learning_rate': 0.02320738586849919, 'lambda_l1': 0.9784448539618956, 'lambda_l2': 8.621915175594918, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:21,616]\u001b[0m Trial 60 finished with value: 4.334334786890682 and parameters: {'learning_rate': 0.09074899442289672, 'lambda_l1': 7.740473329245914, 'lambda_l2': 3.331451526954967, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:27,684]\u001b[0m Trial 61 finished with value: 4.402059968311893 and parameters: {'learning_rate': 0.023991180074923332, 'lambda_l1': 1.3248763562549533, 'lambda_l2': 0.5342718273339808, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:32,682]\u001b[0m Trial 62 finished with value: 4.593943365926479 and parameters: {'learning_rate': 0.07728749410177485, 'lambda_l1': 1.469466462534284, 'lambda_l2': 0.7952208350723367, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:37,538]\u001b[0m Trial 63 finished with value: 4.1988891275625555 and parameters: {'learning_rate': 0.025291353775431635, 'lambda_l1': 4.205394672595589, 'lambda_l2': 5.573687917665481, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:43,018]\u001b[0m Trial 64 finished with value: 4.571369786188724 and parameters: {'learning_rate': 0.02776246261863275, 'lambda_l1': 1.314828001596448, 'lambda_l2': 0.5537432136582362, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:47,116]\u001b[0m Trial 65 finished with value: 4.289185536964374 and parameters: {'learning_rate': 0.04615791611324749, 'lambda_l1': 6.832813358643991, 'lambda_l2': 6.956254459432317, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:51,970]\u001b[0m Trial 66 finished with value: 4.176313457374002 and parameters: {'learning_rate': 0.018933945211953403, 'lambda_l1': 7.885455125179731, 'lambda_l2': 0.5684807737639223, 'bagging_freq': 5, 'min_child_samples': 79}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:17:56,239]\u001b[0m Trial 67 finished with value: 4.413348717978393 and parameters: {'learning_rate': 0.07796334862302656, 'lambda_l1': 2.5942256508593236, 'lambda_l2': 3.7381313855874825, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:02,980]\u001b[0m Trial 68 finished with value: 4.424634593275047 and parameters: {'learning_rate': 0.03771442712257098, 'lambda_l1': 1.9705428098858533, 'lambda_l2': 4.5985588429615145, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:10,223]\u001b[0m Trial 69 finished with value: 4.187602729653202 and parameters: {'learning_rate': 0.00861868825167664, 'lambda_l1': 5.188351493126908, 'lambda_l2': 3.0681010023838597, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:19,658]\u001b[0m Trial 70 finished with value: 4.966423501939947 and parameters: {'learning_rate': 0.06491145420114439, 'lambda_l1': 0.35362436720128476, 'lambda_l2': 4.304024400776587, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:25,721]\u001b[0m Trial 71 finished with value: 4.345623536557182 and parameters: {'learning_rate': 0.06845785854977995, 'lambda_l1': 2.7759609845416997, 'lambda_l2': 1.2886056633745961, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:29,615]\u001b[0m Trial 72 finished with value: 4.210175002859209 and parameters: {'learning_rate': 0.01952595828333363, 'lambda_l1': 9.039839550242531, 'lambda_l2': 5.438059505335204, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:33,332]\u001b[0m Trial 73 finished with value: 4.176314241293051 and parameters: {'learning_rate': 0.046401792215090006, 'lambda_l1': 7.2416763688737555, 'lambda_l2': 3.9902532230407664, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:37,454]\u001b[0m Trial 74 finished with value: 4.255324775398216 and parameters: {'learning_rate': 0.07026258337080116, 'lambda_l1': 3.2772040222939847, 'lambda_l2': 7.567786429801105, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:41,352]\u001b[0m Trial 75 finished with value: 4.2214632299130095 and parameters: {'learning_rate': 0.016893343426040385, 'lambda_l1': 7.963914747209402, 'lambda_l2': 9.591666030760559, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:45,479]\u001b[0m Trial 76 finished with value: 4.142454786258643 and parameters: {'learning_rate': 0.0859145417751619, 'lambda_l1': 4.5722345389663355, 'lambda_l2': 9.518744768808617, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:48,892]\u001b[0m Trial 77 finished with value: 4.323049434206728 and parameters: {'learning_rate': 0.09097552812286111, 'lambda_l1': 8.15523818953045, 'lambda_l2': 1.5941446428954145, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:55,207]\u001b[0m Trial 78 finished with value: 4.10858932117819 and parameters: {'learning_rate': 0.007208582250311225, 'lambda_l1': 4.2403225246580964, 'lambda_l2': 2.586840676307236, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:18:59,597]\u001b[0m Trial 79 finished with value: 4.22146296860666 and parameters: {'learning_rate': 0.09593928946448389, 'lambda_l1': 3.5536884911656075, 'lambda_l2': 3.5670689104583597, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:03,129]\u001b[0m Trial 80 finished with value: 4.255325559317265 and parameters: {'learning_rate': 0.040724690579557264, 'lambda_l1': 9.292914173734225, 'lambda_l2': 0.9961493112165639, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:07,097]\u001b[0m Trial 81 finished with value: 4.097302923268837 and parameters: {'learning_rate': 0.04596207729384763, 'lambda_l1': 3.2670088244155915, 'lambda_l2': 2.327441300463127, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:20,981]\u001b[0m Trial 82 finished with value: 4.142452957114195 and parameters: {'learning_rate': 0.0025450003802359933, 'lambda_l1': 4.2879572306944205, 'lambda_l2': 0.6807407490664613, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:29,111]\u001b[0m Trial 83 finished with value: 4.571367957044275 and parameters: {'learning_rate': 0.026065928178562344, 'lambda_l1': 1.310552320842025, 'lambda_l2': 0.12036223885618046, 'bagging_freq': 1, 'min_child_samples': 64}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:35,888]\u001b[0m Trial 84 finished with value: 4.300473764018174 and parameters: {'learning_rate': 0.09745136506898698, 'lambda_l1': 9.90345001570549, 'lambda_l2': 4.090540959640075, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:43,114]\u001b[0m Trial 85 finished with value: 4.289186843496123 and parameters: {'learning_rate': 0.04954022930832498, 'lambda_l1': 9.894097772950216, 'lambda_l2': 0.6530420808647599, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:49,653]\u001b[0m Trial 86 finished with value: 4.289186582189772 and parameters: {'learning_rate': 0.024900443387580826, 'lambda_l1': 6.625045718701713, 'lambda_l2': 2.4606318574490125, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:19:55,231]\u001b[0m Trial 87 finished with value: 4.232750150435062 and parameters: {'learning_rate': 0.04298480985514908, 'lambda_l1': 5.5468780910673114, 'lambda_l2': 2.870515206325782, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:00,873]\u001b[0m Trial 88 finished with value: 4.210176570697307 and parameters: {'learning_rate': 0.036694010488103335, 'lambda_l1': 8.286569147270809, 'lambda_l2': 9.249669120282253, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:05,331]\u001b[0m Trial 89 finished with value: 4.266611695920268 and parameters: {'learning_rate': 0.03550341757976376, 'lambda_l1': 8.149664795552809, 'lambda_l2': 9.85491427657806, 'bagging_freq': 7, 'min_child_samples': 91}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:09,578]\u001b[0m Trial 90 finished with value: 4.210176832003657 and parameters: {'learning_rate': 0.03035907024133896, 'lambda_l1': 9.92011243422463, 'lambda_l2': 2.4942004180703115, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:13,966]\u001b[0m Trial 91 finished with value: 4.1876009005087536 and parameters: {'learning_rate': 0.024108605291341536, 'lambda_l1': 6.897682653879821, 'lambda_l2': 0.583563599222323, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:19,232]\u001b[0m Trial 92 finished with value: 4.142451650582445 and parameters: {'learning_rate': 0.02797125265113029, 'lambda_l1': 3.790568966983716, 'lambda_l2': 3.7429618394661985, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:24,653]\u001b[0m Trial 93 finished with value: 4.176314241293051 and parameters: {'learning_rate': 0.01801345680571666, 'lambda_l1': 4.492916492384464, 'lambda_l2': 3.0446840807285107, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:29,140]\u001b[0m Trial 94 finished with value: 4.1988893888689045 and parameters: {'learning_rate': 0.050736556291436884, 'lambda_l1': 9.425835997553468, 'lambda_l2': 6.33997698110663, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:33,637]\u001b[0m Trial 95 finished with value: 4.232749366516013 and parameters: {'learning_rate': 0.07532572132674885, 'lambda_l1': 6.995750605251763, 'lambda_l2': 9.679655666362615, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:41,741]\u001b[0m Trial 96 finished with value: 4.244038116182513 and parameters: {'learning_rate': 0.008016108040236627, 'lambda_l1': 2.927940321477248, 'lambda_l2': 1.5235470653537573, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:46,353]\u001b[0m Trial 97 finished with value: 4.2327514569668105 and parameters: {'learning_rate': 0.06080766259806732, 'lambda_l1': 3.82808059775046, 'lambda_l2': 8.953858843928241, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:50,959]\u001b[0m Trial 98 finished with value: 4.119877025619292 and parameters: {'learning_rate': 0.028207533416892066, 'lambda_l1': 5.922304191696063, 'lambda_l2': 8.967611583276486, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2022-02-19 09:20:55,690]\u001b[0m Trial 99 finished with value: 4.221463752525709 and parameters: {'learning_rate': 0.027893623993008442, 'lambda_l1': 4.554441499945828, 'lambda_l2': 4.017135359778851, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 6 with value: 4.029577741847626.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'learning_rate': 0.027191005598358072,\n",
       " 'lambda_l1': 7.742336896599829,\n",
       " 'lambda_l2': 4.561503327603981,\n",
       " 'bagging_freq': 4,\n",
       " 'min_child_samples': 6,\n",
       " 'max_depth': -1,\n",
       " 'random_state': 0,\n",
       " 'num_boost_round': 10000,\n",
       " 'verbosity': -100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lightgbm\n",
    "### \n",
    "\n",
    "# \n",
    "lgbm = models.Lgbm(config[\"model_params\"][\"Lgbm\"])\n",
    "optimized_params = beyesian_optimization(lgbm, X_train, y_train, {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'lambda_l1': [1e-8, 10.0],\n",
    "    'lambda_l2': [1e-8, 10.0],\n",
    "    'bagging_freq': [1, 7],\n",
    "    'min_child_samples': [5, 100],\n",
    "    'learning_rate': [0.001, 0.1],\n",
    "    'max_depth': -1,\n",
    "    'random_state': 0,\n",
    "    'num_boost_round': 10000,\n",
    "    'verbosity': -100,\n",
    "}, n_trials)\n",
    "optimized_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'learning_rate': 0.027191005598358072, 'lambda_l1': 7.742336896599829, 'lambda_l2': 4.561503327603981, 'bagging_freq': 4, 'min_child_samples': 6, 'max_depth': -1, 'random_state': 0, 'num_boost_round': 10000, 'verbosity': -100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/yutahirai/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795098039215686\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)\n",
    "print(cross_validation_score(models.Lgbm(optimized_params), X_train, y_train))\n",
    "with open('./config/Lgbm-depth-inf.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 09:22:09,440]\u001b[0m A new study created in memory with name: no-name-74d34cb5-c817-4133-853c-3f2c3aaa6fd6\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:11,171]\u001b[0m Trial 0 finished with value: 4.165024446401151 and parameters: {'n_estimators': 562, 'max_depth': 184, 'min_samples_split': 39, 'min_samples_leaf': 18}. Best is trial 0 with value: 4.165024446401151.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:12,408]\u001b[0m Trial 1 finished with value: 4.21017343502111 and parameters: {'n_estimators': 434, 'max_depth': 166, 'min_samples_split': 29, 'min_samples_leaf': 29}. Best is trial 0 with value: 4.165024446401151.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:15,405]\u001b[0m Trial 2 finished with value: 4.187600116589705 and parameters: {'n_estimators': 987, 'max_depth': 99, 'min_samples_split': 51, 'min_samples_leaf': 17}. Best is trial 0 with value: 4.165024446401151.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:17,625]\u001b[0m Trial 3 finished with value: 4.142452434501495 and parameters: {'n_estimators': 582, 'max_depth': 237, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:17,698]\u001b[0m Trial 4 finished with value: 4.232748843903313 and parameters: {'n_estimators': 21, 'max_depth': 214, 'min_samples_split': 51, 'min_samples_leaf': 28}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:20,630]\u001b[0m Trial 5 finished with value: 4.244036809650765 and parameters: {'n_estimators': 1003, 'max_depth': 205, 'min_samples_split': 31, 'min_samples_leaf': 25}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:20,990]\u001b[0m Trial 6 finished with value: 4.2327488439033125 and parameters: {'n_estimators': 122, 'max_depth': 164, 'min_samples_split': 11, 'min_samples_leaf': 31}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:22,571]\u001b[0m Trial 7 finished with value: 4.210174480246509 and parameters: {'n_estimators': 535, 'max_depth': 107, 'min_samples_split': 18, 'min_samples_leaf': 25}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:23,991]\u001b[0m Trial 8 finished with value: 4.221461139462211 and parameters: {'n_estimators': 468, 'max_depth': 146, 'min_samples_split': 3, 'min_samples_leaf': 20}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:25,845]\u001b[0m Trial 9 finished with value: 4.176313196067652 and parameters: {'n_estimators': 627, 'max_depth': 158, 'min_samples_split': 61, 'min_samples_leaf': 22}. Best is trial 3 with value: 4.142452434501495.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:27,191]\u001b[0m Trial 10 finished with value: 4.131164207447694 and parameters: {'n_estimators': 369, 'max_depth': 112, 'min_samples_split': 45, 'min_samples_leaf': 2}. Best is trial 10 with value: 4.131164207447694.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:29,675]\u001b[0m Trial 11 finished with value: 4.074727775692983 and parameters: {'n_estimators': 683, 'max_depth': 172, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 11 with value: 4.074727775692983.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:30,697]\u001b[0m Trial 12 finished with value: 4.119875980393893 and parameters: {'n_estimators': 323, 'max_depth': 94, 'min_samples_split': 37, 'min_samples_leaf': 15}. Best is trial 11 with value: 4.074727775692983.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:34,215]\u001b[0m Trial 13 finished with value: 4.1198765030065925 and parameters: {'n_estimators': 1013, 'max_depth': 27, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 4.074727775692983.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:36,431]\u001b[0m Trial 14 finished with value: 4.097302139349788 and parameters: {'n_estimators': 669, 'max_depth': 65, 'min_samples_split': 31, 'min_samples_leaf': 8}. Best is trial 11 with value: 4.074727775692983.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:36,990]\u001b[0m Trial 15 finished with value: 4.0521521055044305 and parameters: {'n_estimators': 163, 'max_depth': 29, 'min_samples_split': 43, 'min_samples_leaf': 5}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:37,678]\u001b[0m Trial 16 finished with value: 4.097302923268837 and parameters: {'n_estimators': 202, 'max_depth': 95, 'min_samples_split': 53, 'min_samples_leaf': 4}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:40,342]\u001b[0m Trial 17 finished with value: 4.131162900915944 and parameters: {'n_estimators': 859, 'max_depth': 25, 'min_samples_split': 63, 'min_samples_leaf': 15}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:43,826]\u001b[0m Trial 18 finished with value: 4.063439548639182 and parameters: {'n_estimators': 1001, 'max_depth': 155, 'min_samples_split': 48, 'min_samples_leaf': 2}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:44,866]\u001b[0m Trial 19 finished with value: 4.097302400656138 and parameters: {'n_estimators': 290, 'max_depth': 31, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:45,840]\u001b[0m Trial 20 finished with value: 4.244036809650765 and parameters: {'n_estimators': 326, 'max_depth': 107, 'min_samples_split': 6, 'min_samples_leaf': 23}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:48,015]\u001b[0m Trial 21 finished with value: 4.10858905987184 and parameters: {'n_estimators': 581, 'max_depth': 68, 'min_samples_split': 34, 'min_samples_leaf': 4}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:49,878]\u001b[0m Trial 22 finished with value: 4.176312412148603 and parameters: {'n_estimators': 590, 'max_depth': 238, 'min_samples_split': 22, 'min_samples_leaf': 22}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:50,404]\u001b[0m Trial 23 finished with value: 4.10858984379089 and parameters: {'n_estimators': 135, 'max_depth': 184, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:52,060]\u001b[0m Trial 24 finished with value: 4.289185014351674 and parameters: {'n_estimators': 601, 'max_depth': 6, 'min_samples_split': 54, 'min_samples_leaf': 1}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:54,317]\u001b[0m Trial 25 finished with value: 4.21017369632746 and parameters: {'n_estimators': 695, 'max_depth': 70, 'min_samples_split': 48, 'min_samples_leaf': 31}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:55,089]\u001b[0m Trial 26 finished with value: 4.176314502599401 and parameters: {'n_estimators': 255, 'max_depth': 148, 'min_samples_split': 39, 'min_samples_leaf': 19}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:55,833]\u001b[0m Trial 27 finished with value: 4.277898616442321 and parameters: {'n_estimators': 229, 'max_depth': 244, 'min_samples_split': 30, 'min_samples_leaf': 28}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:22:58,195]\u001b[0m Trial 28 finished with value: 4.1537388324108475 and parameters: {'n_estimators': 717, 'max_depth': 77, 'min_samples_split': 53, 'min_samples_leaf': 13}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:01,865]\u001b[0m Trial 29 finished with value: 4.1763126734549525 and parameters: {'n_estimators': 903, 'max_depth': 149, 'min_samples_split': 57, 'min_samples_leaf': 23}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:04,178]\u001b[0m Trial 30 finished with value: 4.1424506053570465 and parameters: {'n_estimators': 743, 'max_depth': 129, 'min_samples_split': 62, 'min_samples_leaf': 21}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:05,821]\u001b[0m Trial 31 finished with value: 4.131163946141344 and parameters: {'n_estimators': 435, 'max_depth': 156, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:08,141]\u001b[0m Trial 32 finished with value: 4.142451389276095 and parameters: {'n_estimators': 677, 'max_depth': 75, 'min_samples_split': 40, 'min_samples_leaf': 14}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:08,586]\u001b[0m Trial 33 finished with value: 4.142450866663396 and parameters: {'n_estimators': 139, 'max_depth': 77, 'min_samples_split': 37, 'min_samples_leaf': 19}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:10,418]\u001b[0m Trial 34 finished with value: 4.131164207447694 and parameters: {'n_estimators': 589, 'max_depth': 168, 'min_samples_split': 43, 'min_samples_leaf': 14}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:12,987]\u001b[0m Trial 35 finished with value: 4.266609866775821 and parameters: {'n_estimators': 919, 'max_depth': 95, 'min_samples_split': 29, 'min_samples_leaf': 29}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:15,280]\u001b[0m Trial 36 finished with value: 4.198887037111757 and parameters: {'n_estimators': 826, 'max_depth': 181, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:17,334]\u001b[0m Trial 37 finished with value: 4.21017395763381 and parameters: {'n_estimators': 732, 'max_depth': 256, 'min_samples_split': 11, 'min_samples_leaf': 28}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:17,810]\u001b[0m Trial 38 finished with value: 4.300473502711824 and parameters: {'n_estimators': 167, 'max_depth': 158, 'min_samples_split': 9, 'min_samples_leaf': 28}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:20,673]\u001b[0m Trial 39 finished with value: 4.10858984379089 and parameters: {'n_estimators': 827, 'max_depth': 146, 'min_samples_split': 27, 'min_samples_leaf': 3}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:22,729]\u001b[0m Trial 40 finished with value: 4.232748843903313 and parameters: {'n_estimators': 715, 'max_depth': 117, 'min_samples_split': 47, 'min_samples_leaf': 28}. Best is trial 15 with value: 4.0521521055044305.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:26,058]\u001b[0m Trial 41 finished with value: 4.040864923676028 and parameters: {'n_estimators': 999, 'max_depth': 220, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:28,835]\u001b[0m Trial 42 finished with value: 4.153738571104498 and parameters: {'n_estimators': 748, 'max_depth': 44, 'min_samples_split': 34, 'min_samples_leaf': 2}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:29,306]\u001b[0m Trial 43 finished with value: 4.368192935393342 and parameters: {'n_estimators': 205, 'max_depth': 5, 'min_samples_split': 52, 'min_samples_leaf': 8}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:30,539]\u001b[0m Trial 44 finished with value: 4.153737525879099 and parameters: {'n_estimators': 354, 'max_depth': 238, 'min_samples_split': 46, 'min_samples_leaf': 2}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:31,140]\u001b[0m Trial 45 finished with value: 4.052151060279031 and parameters: {'n_estimators': 169, 'max_depth': 160, 'min_samples_split': 38, 'min_samples_leaf': 8}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:34,017]\u001b[0m Trial 46 finished with value: 4.1537388324108475 and parameters: {'n_estimators': 957, 'max_depth': 158, 'min_samples_split': 35, 'min_samples_leaf': 19}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:36,461]\u001b[0m Trial 47 finished with value: 4.119876503006592 and parameters: {'n_estimators': 748, 'max_depth': 80, 'min_samples_split': 27, 'min_samples_leaf': 7}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:37,034]\u001b[0m Trial 48 finished with value: 4.1424506053570465 and parameters: {'n_estimators': 191, 'max_depth': 242, 'min_samples_split': 48, 'min_samples_leaf': 16}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:37,754]\u001b[0m Trial 49 finished with value: 4.097302400656137 and parameters: {'n_estimators': 233, 'max_depth': 66, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:38,819]\u001b[0m Trial 50 finished with value: 4.097303707187886 and parameters: {'n_estimators': 320, 'max_depth': 179, 'min_samples_split': 25, 'min_samples_leaf': 6}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:38,909]\u001b[0m Trial 51 finished with value: 4.25532033319027 and parameters: {'n_estimators': 26, 'max_depth': 18, 'min_samples_split': 44, 'min_samples_leaf': 15}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:40,636]\u001b[0m Trial 52 finished with value: 4.119876764312942 and parameters: {'n_estimators': 550, 'max_depth': 230, 'min_samples_split': 64, 'min_samples_leaf': 7}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:42,607]\u001b[0m Trial 53 finished with value: 4.244036809650765 and parameters: {'n_estimators': 679, 'max_depth': 68, 'min_samples_split': 3, 'min_samples_leaf': 25}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:43,560]\u001b[0m Trial 54 finished with value: 4.2666106506948696 and parameters: {'n_estimators': 328, 'max_depth': 99, 'min_samples_split': 39, 'min_samples_leaf': 27}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:45,426]\u001b[0m Trial 55 finished with value: 4.289186059577073 and parameters: {'n_estimators': 645, 'max_depth': 224, 'min_samples_split': 19, 'min_samples_leaf': 26}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:46,064]\u001b[0m Trial 56 finished with value: 4.153738309798148 and parameters: {'n_estimators': 191, 'max_depth': 244, 'min_samples_split': 45, 'min_samples_leaf': 7}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:49,525]\u001b[0m Trial 57 finished with value: 4.052152889423479 and parameters: {'n_estimators': 971, 'max_depth': 188, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:51,054]\u001b[0m Trial 58 finished with value: 4.255322423641069 and parameters: {'n_estimators': 531, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 14}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:52,269]\u001b[0m Trial 59 finished with value: 4.198887298418106 and parameters: {'n_estimators': 384, 'max_depth': 119, 'min_samples_split': 19, 'min_samples_leaf': 19}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:55,304]\u001b[0m Trial 60 finished with value: 4.131164207447694 and parameters: {'n_estimators': 885, 'max_depth': 31, 'min_samples_split': 34, 'min_samples_leaf': 5}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:57,760]\u001b[0m Trial 61 finished with value: 4.052153412036179 and parameters: {'n_estimators': 735, 'max_depth': 102, 'min_samples_split': 37, 'min_samples_leaf': 6}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:23:58,195]\u001b[0m Trial 62 finished with value: 4.21017395763381 and parameters: {'n_estimators': 149, 'max_depth': 125, 'min_samples_split': 24, 'min_samples_leaf': 31}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:00,792]\u001b[0m Trial 63 finished with value: 4.074726469161234 and parameters: {'n_estimators': 784, 'max_depth': 192, 'min_samples_split': 58, 'min_samples_leaf': 3}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:02,547]\u001b[0m Trial 64 finished with value: 4.142450082744347 and parameters: {'n_estimators': 566, 'max_depth': 150, 'min_samples_split': 62, 'min_samples_leaf': 10}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:03,257]\u001b[0m Trial 65 finished with value: 4.255323991479167 and parameters: {'n_estimators': 247, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 30}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:05,332]\u001b[0m Trial 66 finished with value: 4.1650257529329 and parameters: {'n_estimators': 686, 'max_depth': 201, 'min_samples_split': 19, 'min_samples_leaf': 19}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:05,533]\u001b[0m Trial 67 finished with value: 4.131162639609595 and parameters: {'n_estimators': 66, 'max_depth': 125, 'min_samples_split': 63, 'min_samples_leaf': 29}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:06,524]\u001b[0m Trial 68 finished with value: 4.198887298418106 and parameters: {'n_estimators': 347, 'max_depth': 247, 'min_samples_split': 16, 'min_samples_leaf': 31}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:09,227]\u001b[0m Trial 69 finished with value: 4.1988865144990575 and parameters: {'n_estimators': 964, 'max_depth': 205, 'min_samples_split': 41, 'min_samples_leaf': 28}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:10,328]\u001b[0m Trial 70 finished with value: 4.108587230727392 and parameters: {'n_estimators': 301, 'max_depth': 218, 'min_samples_split': 40, 'min_samples_leaf': 1}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:11,406]\u001b[0m Trial 71 finished with value: 4.16502549162655 and parameters: {'n_estimators': 356, 'max_depth': 38, 'min_samples_split': 63, 'min_samples_leaf': 16}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:13,151]\u001b[0m Trial 72 finished with value: 4.097302139349788 and parameters: {'n_estimators': 510, 'max_depth': 164, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:15,864]\u001b[0m Trial 73 finished with value: 4.10858932117819 and parameters: {'n_estimators': 842, 'max_depth': 49, 'min_samples_split': 34, 'min_samples_leaf': 8}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:16,165]\u001b[0m Trial 74 finished with value: 4.210174218940159 and parameters: {'n_estimators': 101, 'max_depth': 221, 'min_samples_split': 63, 'min_samples_leaf': 31}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:19,450]\u001b[0m Trial 75 finished with value: 4.153739355023547 and parameters: {'n_estimators': 929, 'max_depth': 199, 'min_samples_split': 22, 'min_samples_leaf': 3}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:21,056]\u001b[0m Trial 76 finished with value: 4.244038116182514 and parameters: {'n_estimators': 418, 'max_depth': 60, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:22,423]\u001b[0m Trial 77 finished with value: 4.639063872154315 and parameters: {'n_estimators': 744, 'max_depth': 3, 'min_samples_split': 50, 'min_samples_leaf': 5}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:22,695]\u001b[0m Trial 78 finished with value: 4.153739355023547 and parameters: {'n_estimators': 82, 'max_depth': 23, 'min_samples_split': 44, 'min_samples_leaf': 8}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:23,960]\u001b[0m Trial 79 finished with value: 4.1876009005087536 and parameters: {'n_estimators': 431, 'max_depth': 143, 'min_samples_split': 56, 'min_samples_leaf': 24}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:24,863]\u001b[0m Trial 80 finished with value: 4.063439809945532 and parameters: {'n_estimators': 277, 'max_depth': 34, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:25,655]\u001b[0m Trial 81 finished with value: 4.232749627822362 and parameters: {'n_estimators': 269, 'max_depth': 117, 'min_samples_split': 45, 'min_samples_leaf': 23}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:26,507]\u001b[0m Trial 82 finished with value: 4.289186320883423 and parameters: {'n_estimators': 291, 'max_depth': 98, 'min_samples_split': 13, 'min_samples_leaf': 26}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:26,694]\u001b[0m Trial 83 finished with value: 4.1763126734549525 and parameters: {'n_estimators': 59, 'max_depth': 179, 'min_samples_split': 51, 'min_samples_leaf': 25}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:27,543]\u001b[0m Trial 84 finished with value: 4.097301878043438 and parameters: {'n_estimators': 266, 'max_depth': 96, 'min_samples_split': 39, 'min_samples_leaf': 9}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:28,893]\u001b[0m Trial 85 finished with value: 4.086015480134085 and parameters: {'n_estimators': 380, 'max_depth': 51, 'min_samples_split': 30, 'min_samples_leaf': 2}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:31,480]\u001b[0m Trial 86 finished with value: 4.10858905987184 and parameters: {'n_estimators': 819, 'max_depth': 20, 'min_samples_split': 34, 'min_samples_leaf': 10}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:33,529]\u001b[0m Trial 87 finished with value: 4.153737787185449 and parameters: {'n_estimators': 592, 'max_depth': 246, 'min_samples_split': 42, 'min_samples_leaf': 2}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:34,809]\u001b[0m Trial 88 finished with value: 4.232749889128712 and parameters: {'n_estimators': 441, 'max_depth': 131, 'min_samples_split': 35, 'min_samples_leaf': 22}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:35,632]\u001b[0m Trial 89 finished with value: 4.187599855283355 and parameters: {'n_estimators': 285, 'max_depth': 33, 'min_samples_split': 26, 'min_samples_leaf': 31}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:36,234]\u001b[0m Trial 90 finished with value: 4.097300310205339 and parameters: {'n_estimators': 192, 'max_depth': 232, 'min_samples_split': 36, 'min_samples_leaf': 15}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:38,998]\u001b[0m Trial 91 finished with value: 4.131163423528645 and parameters: {'n_estimators': 904, 'max_depth': 118, 'min_samples_split': 47, 'min_samples_leaf': 13}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:41,893]\u001b[0m Trial 92 finished with value: 4.142451127969746 and parameters: {'n_estimators': 926, 'max_depth': 177, 'min_samples_split': 46, 'min_samples_leaf': 11}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:44,615]\u001b[0m Trial 93 finished with value: 4.040866491514127 and parameters: {'n_estimators': 775, 'max_depth': 163, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:47,076]\u001b[0m Trial 94 finished with value: 4.142451127969746 and parameters: {'n_estimators': 816, 'max_depth': 246, 'min_samples_split': 30, 'min_samples_leaf': 19}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:49,755]\u001b[0m Trial 95 finished with value: 4.176313196067652 and parameters: {'n_estimators': 879, 'max_depth': 118, 'min_samples_split': 61, 'min_samples_leaf': 19}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:52,719]\u001b[0m Trial 96 finished with value: 4.074726991773934 and parameters: {'n_estimators': 841, 'max_depth': 233, 'min_samples_split': 53, 'min_samples_leaf': 6}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:54,740]\u001b[0m Trial 97 finished with value: 4.10858932117819 and parameters: {'n_estimators': 644, 'max_depth': 102, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:55,494]\u001b[0m Trial 98 finished with value: 4.244036548344415 and parameters: {'n_estimators': 265, 'max_depth': 218, 'min_samples_split': 4, 'min_samples_leaf': 31}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 09:24:56,743]\u001b[0m Trial 99 finished with value: 4.142452173195145 and parameters: {'n_estimators': 364, 'max_depth': 92, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 41 with value: 4.040864923676028.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rf = models.RandomForest({})\n",
    "optimized_params = beyesian_optimization(rf, X_train, y_train, {\n",
    "    'n_estimators': [1, 1024],\n",
    "    'max_depth': [1, 256],\n",
    "    'min_samples_split': [2, 64],\n",
    "    'min_samples_leaf': [1, 32],\n",
    "    'random_state': 0\n",
    "}, n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 999, 'max_depth': 220, 'min_samples_split': 2, 'min_samples_leaf': 12, 'random_state': 0}\n",
      "0.8794117647058823\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)\n",
    "print(cross_validation_score(models.RandomForest(optimized_params), X_train, y_train))\n",
    "with open('./config/RandomForest.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 12:13:09,408]\u001b[0m A new study created in memory with name: no-name-60c7532d-d034-4f19-94a0-4bc89d30833c\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:10,935]\u001b[0m Trial 0 finished with value: 4.402063365294439 and parameters: {'n_estimators': 563, 'max_depth': 184, 'min_samples_split': 39, 'min_samples_leaf': 18}. Best is trial 0 with value: 4.402063365294439.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:12,066]\u001b[0m Trial 1 finished with value: 4.3569151605935295 and parameters: {'n_estimators': 435, 'max_depth': 166, 'min_samples_split': 29, 'min_samples_leaf': 29}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:14,806]\u001b[0m Trial 2 finished with value: 4.4133508084291915 and parameters: {'n_estimators': 987, 'max_depth': 99, 'min_samples_split': 51, 'min_samples_leaf': 17}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:16,789]\u001b[0m Trial 3 finished with value: 4.368196332375888 and parameters: {'n_estimators': 583, 'max_depth': 237, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:16,859]\u001b[0m Trial 4 finished with value: 4.41335263757364 and parameters: {'n_estimators': 22, 'max_depth': 214, 'min_samples_split': 51, 'min_samples_leaf': 28}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:19,544]\u001b[0m Trial 5 finished with value: 4.413351069735541 and parameters: {'n_estimators': 1003, 'max_depth': 205, 'min_samples_split': 31, 'min_samples_leaf': 25}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:19,864]\u001b[0m Trial 6 finished with value: 4.402063626600789 and parameters: {'n_estimators': 122, 'max_depth': 164, 'min_samples_split': 11, 'min_samples_leaf': 31}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:21,429]\u001b[0m Trial 7 finished with value: 4.379489262943984 and parameters: {'n_estimators': 535, 'max_depth': 107, 'min_samples_split': 18, 'min_samples_leaf': 25}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:22,702]\u001b[0m Trial 8 finished with value: 4.379489001637634 and parameters: {'n_estimators': 468, 'max_depth': 146, 'min_samples_split': 3, 'min_samples_leaf': 20}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:24,418]\u001b[0m Trial 9 finished with value: 4.413350547122842 and parameters: {'n_estimators': 628, 'max_depth': 158, 'min_samples_split': 61, 'min_samples_leaf': 22}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:25,617]\u001b[0m Trial 10 finished with value: 4.402057877861095 and parameters: {'n_estimators': 369, 'max_depth': 112, 'min_samples_split': 45, 'min_samples_leaf': 2}. Best is trial 1 with value: 4.3569151605935295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:27,889]\u001b[0m Trial 11 finished with value: 4.2553252980109155 and parameters: {'n_estimators': 684, 'max_depth': 172, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:28,827]\u001b[0m Trial 12 finished with value: 4.447211831301699 and parameters: {'n_estimators': 324, 'max_depth': 94, 'min_samples_split': 37, 'min_samples_leaf': 15}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:32,080]\u001b[0m Trial 13 finished with value: 4.277900184280419 and parameters: {'n_estimators': 1013, 'max_depth': 27, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:34,089]\u001b[0m Trial 14 finished with value: 4.300474547937224 and parameters: {'n_estimators': 670, 'max_depth': 65, 'min_samples_split': 31, 'min_samples_leaf': 8}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:34,685]\u001b[0m Trial 15 finished with value: 4.3681973776012875 and parameters: {'n_estimators': 164, 'max_depth': 29, 'min_samples_split': 43, 'min_samples_leaf': 5}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:35,397]\u001b[0m Trial 16 finished with value: 4.379483252897941 and parameters: {'n_estimators': 203, 'max_depth': 95, 'min_samples_split': 53, 'min_samples_leaf': 4}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:37,896]\u001b[0m Trial 17 finished with value: 4.3794884790249355 and parameters: {'n_estimators': 859, 'max_depth': 25, 'min_samples_split': 63, 'min_samples_leaf': 15}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:41,058]\u001b[0m Trial 18 finished with value: 4.334334002971632 and parameters: {'n_estimators': 1001, 'max_depth': 155, 'min_samples_split': 48, 'min_samples_leaf': 2}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:42,000]\u001b[0m Trial 19 finished with value: 4.289186059577073 and parameters: {'n_estimators': 291, 'max_depth': 31, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:42,880]\u001b[0m Trial 20 finished with value: 4.413351331041891 and parameters: {'n_estimators': 327, 'max_depth': 107, 'min_samples_split': 6, 'min_samples_leaf': 23}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:44,672]\u001b[0m Trial 21 finished with value: 4.300473764018174 and parameters: {'n_estimators': 581, 'max_depth': 68, 'min_samples_split': 34, 'min_samples_leaf': 4}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:46,290]\u001b[0m Trial 22 finished with value: 4.413351331041891 and parameters: {'n_estimators': 591, 'max_depth': 238, 'min_samples_split': 22, 'min_samples_leaf': 22}. Best is trial 11 with value: 4.2553252980109155.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:46,723]\u001b[0m Trial 23 finished with value: 4.244038116182513 and parameters: {'n_estimators': 136, 'max_depth': 184, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:47,972]\u001b[0m Trial 24 finished with value: 4.390778273916835 and parameters: {'n_estimators': 602, 'max_depth': 6, 'min_samples_split': 54, 'min_samples_leaf': 1}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:49,840]\u001b[0m Trial 25 finished with value: 4.368202342421932 and parameters: {'n_estimators': 695, 'max_depth': 70, 'min_samples_split': 48, 'min_samples_leaf': 31}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:50,571]\u001b[0m Trial 26 finished with value: 4.356914115368131 and parameters: {'n_estimators': 256, 'max_depth': 148, 'min_samples_split': 39, 'min_samples_leaf': 19}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:51,193]\u001b[0m Trial 27 finished with value: 4.379489785556684 and parameters: {'n_estimators': 230, 'max_depth': 244, 'min_samples_split': 30, 'min_samples_leaf': 28}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:53,277]\u001b[0m Trial 28 finished with value: 4.390774615627938 and parameters: {'n_estimators': 717, 'max_depth': 77, 'min_samples_split': 53, 'min_samples_leaf': 13}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:55,741]\u001b[0m Trial 29 finished with value: 4.402064410519839 and parameters: {'n_estimators': 903, 'max_depth': 149, 'min_samples_split': 57, 'min_samples_leaf': 23}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:57,724]\u001b[0m Trial 30 finished with value: 4.390776183466037 and parameters: {'n_estimators': 743, 'max_depth': 129, 'min_samples_split': 62, 'min_samples_leaf': 21}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:13:59,147]\u001b[0m Trial 31 finished with value: 4.3569120249173325 and parameters: {'n_estimators': 435, 'max_depth': 156, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:01,074]\u001b[0m Trial 32 finished with value: 4.379487956412236 and parameters: {'n_estimators': 677, 'max_depth': 75, 'min_samples_split': 40, 'min_samples_leaf': 14}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:01,458]\u001b[0m Trial 33 finished with value: 4.356913854061782 and parameters: {'n_estimators': 140, 'max_depth': 77, 'min_samples_split': 37, 'min_samples_leaf': 19}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:03,094]\u001b[0m Trial 34 finished with value: 4.3682005132774835 and parameters: {'n_estimators': 589, 'max_depth': 168, 'min_samples_split': 43, 'min_samples_leaf': 14}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:05,454]\u001b[0m Trial 35 finished with value: 4.356915421899879 and parameters: {'n_estimators': 919, 'max_depth': 95, 'min_samples_split': 29, 'min_samples_leaf': 29}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:07,685]\u001b[0m Trial 36 finished with value: 4.41335159234824 and parameters: {'n_estimators': 826, 'max_depth': 181, 'min_samples_split': 8, 'min_samples_leaf': 30}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:09,637]\u001b[0m Trial 37 finished with value: 4.390776706078737 and parameters: {'n_estimators': 732, 'max_depth': 256, 'min_samples_split': 11, 'min_samples_leaf': 28}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:10,094]\u001b[0m Trial 38 finished with value: 4.424638774176643 and parameters: {'n_estimators': 168, 'max_depth': 158, 'min_samples_split': 9, 'min_samples_leaf': 28}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:12,830]\u001b[0m Trial 39 finished with value: 4.368197116294938 and parameters: {'n_estimators': 827, 'max_depth': 146, 'min_samples_split': 27, 'min_samples_leaf': 3}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:14,725]\u001b[0m Trial 40 finished with value: 4.379489524250334 and parameters: {'n_estimators': 715, 'max_depth': 117, 'min_samples_split': 47, 'min_samples_leaf': 28}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:17,759]\u001b[0m Trial 41 finished with value: 4.390774615627938 and parameters: {'n_estimators': 999, 'max_depth': 220, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:20,339]\u001b[0m Trial 42 finished with value: 4.334334264277983 and parameters: {'n_estimators': 748, 'max_depth': 44, 'min_samples_split': 34, 'min_samples_leaf': 2}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:20,733]\u001b[0m Trial 43 finished with value: 4.277900445586769 and parameters: {'n_estimators': 206, 'max_depth': 5, 'min_samples_split': 52, 'min_samples_leaf': 8}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:21,944]\u001b[0m Trial 44 finished with value: 4.356908627934787 and parameters: {'n_estimators': 355, 'max_depth': 238, 'min_samples_split': 46, 'min_samples_leaf': 2}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:22,489]\u001b[0m Trial 45 finished with value: 4.379486388574137 and parameters: {'n_estimators': 170, 'max_depth': 160, 'min_samples_split': 38, 'min_samples_leaf': 8}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:25,221]\u001b[0m Trial 46 finished with value: 4.402063365294439 and parameters: {'n_estimators': 957, 'max_depth': 158, 'min_samples_split': 35, 'min_samples_leaf': 19}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:27,547]\u001b[0m Trial 47 finished with value: 4.311761729765625 and parameters: {'n_estimators': 748, 'max_depth': 80, 'min_samples_split': 27, 'min_samples_leaf': 7}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:28,095]\u001b[0m Trial 48 finished with value: 4.390775399546988 and parameters: {'n_estimators': 192, 'max_depth': 242, 'min_samples_split': 48, 'min_samples_leaf': 16}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:28,798]\u001b[0m Trial 49 finished with value: 4.379487433799537 and parameters: {'n_estimators': 234, 'max_depth': 66, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:29,861]\u001b[0m Trial 50 finished with value: 4.311760684540227 and parameters: {'n_estimators': 320, 'max_depth': 179, 'min_samples_split': 25, 'min_samples_leaf': 6}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:29,956]\u001b[0m Trial 51 finished with value: 4.548797774289067 and parameters: {'n_estimators': 27, 'max_depth': 18, 'min_samples_split': 44, 'min_samples_leaf': 15}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:31,599]\u001b[0m Trial 52 finished with value: 4.334336877341479 and parameters: {'n_estimators': 550, 'max_depth': 230, 'min_samples_split': 64, 'min_samples_leaf': 7}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:33,465]\u001b[0m Trial 53 finished with value: 4.390776444772387 and parameters: {'n_estimators': 680, 'max_depth': 68, 'min_samples_split': 3, 'min_samples_leaf': 25}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:34,348]\u001b[0m Trial 54 finished with value: 4.424638512870294 and parameters: {'n_estimators': 329, 'max_depth': 99, 'min_samples_split': 39, 'min_samples_leaf': 27}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:36,055]\u001b[0m Trial 55 finished with value: 4.379489785556684 and parameters: {'n_estimators': 645, 'max_depth': 224, 'min_samples_split': 19, 'min_samples_leaf': 26}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:36,665]\u001b[0m Trial 56 finished with value: 4.334336354728779 and parameters: {'n_estimators': 191, 'max_depth': 244, 'min_samples_split': 45, 'min_samples_leaf': 7}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:39,740]\u001b[0m Trial 57 finished with value: 4.266611957226618 and parameters: {'n_estimators': 971, 'max_depth': 188, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:40,919]\u001b[0m Trial 58 finished with value: 4.435928569068542 and parameters: {'n_estimators': 532, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 14}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:42,077]\u001b[0m Trial 59 finished with value: 4.368201297196533 and parameters: {'n_estimators': 384, 'max_depth': 119, 'min_samples_split': 19, 'min_samples_leaf': 19}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:44,899]\u001b[0m Trial 60 finished with value: 4.289186320883422 and parameters: {'n_estimators': 885, 'max_depth': 31, 'min_samples_split': 34, 'min_samples_leaf': 5}. Best is trial 23 with value: 4.244038116182513.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:47,353]\u001b[0m Trial 61 finished with value: 4.2440373322634635 and parameters: {'n_estimators': 735, 'max_depth': 102, 'min_samples_split': 37, 'min_samples_leaf': 6}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:47,762]\u001b[0m Trial 62 finished with value: 4.356914637980831 and parameters: {'n_estimators': 150, 'max_depth': 125, 'min_samples_split': 24, 'min_samples_leaf': 31}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:50,421]\u001b[0m Trial 63 finished with value: 4.368196593682238 and parameters: {'n_estimators': 784, 'max_depth': 192, 'min_samples_split': 58, 'min_samples_leaf': 3}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:52,067]\u001b[0m Trial 64 finished with value: 4.3569117636109835 and parameters: {'n_estimators': 566, 'max_depth': 150, 'min_samples_split': 62, 'min_samples_leaf': 10}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:52,726]\u001b[0m Trial 65 finished with value: 4.379489524250334 and parameters: {'n_estimators': 248, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 30}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:54,820]\u001b[0m Trial 66 finished with value: 4.413350808429191 and parameters: {'n_estimators': 687, 'max_depth': 201, 'min_samples_split': 19, 'min_samples_leaf': 19}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:54,996]\u001b[0m Trial 67 finished with value: 4.4020651944388876 and parameters: {'n_estimators': 67, 'max_depth': 125, 'min_samples_split': 63, 'min_samples_leaf': 29}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:55,923]\u001b[0m Trial 68 finished with value: 4.323052831189274 and parameters: {'n_estimators': 347, 'max_depth': 247, 'min_samples_split': 16, 'min_samples_leaf': 31}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:58,405]\u001b[0m Trial 69 finished with value: 4.413351331041891 and parameters: {'n_estimators': 965, 'max_depth': 205, 'min_samples_split': 41, 'min_samples_leaf': 28}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:14:59,509]\u001b[0m Trial 70 finished with value: 4.356908366628437 and parameters: {'n_estimators': 301, 'max_depth': 218, 'min_samples_split': 40, 'min_samples_leaf': 1}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:00,699]\u001b[0m Trial 71 finished with value: 4.3682002519711345 and parameters: {'n_estimators': 357, 'max_depth': 38, 'min_samples_split': 63, 'min_samples_leaf': 16}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:02,511]\u001b[0m Trial 72 finished with value: 4.3117609458465775 and parameters: {'n_estimators': 510, 'max_depth': 164, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:05,387]\u001b[0m Trial 73 finished with value: 4.3117614684592755 and parameters: {'n_estimators': 843, 'max_depth': 49, 'min_samples_split': 34, 'min_samples_leaf': 8}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:05,688]\u001b[0m Trial 74 finished with value: 4.379489262943984 and parameters: {'n_estimators': 102, 'max_depth': 221, 'min_samples_split': 63, 'min_samples_leaf': 31}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:08,891]\u001b[0m Trial 75 finished with value: 4.368196332375888 and parameters: {'n_estimators': 929, 'max_depth': 199, 'min_samples_split': 22, 'min_samples_leaf': 3}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:10,511]\u001b[0m Trial 76 finished with value: 4.334334264277982 and parameters: {'n_estimators': 418, 'max_depth': 60, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:11,656]\u001b[0m Trial 77 finished with value: 5.3162827617663595 and parameters: {'n_estimators': 744, 'max_depth': 3, 'min_samples_split': 50, 'min_samples_leaf': 5}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:11,935]\u001b[0m Trial 78 finished with value: 4.289188150027871 and parameters: {'n_estimators': 83, 'max_depth': 23, 'min_samples_split': 44, 'min_samples_leaf': 8}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:13,193]\u001b[0m Trial 79 finished with value: 4.413350808429191 and parameters: {'n_estimators': 432, 'max_depth': 143, 'min_samples_split': 56, 'min_samples_leaf': 24}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:14,015]\u001b[0m Trial 80 finished with value: 4.379486388574137 and parameters: {'n_estimators': 278, 'max_depth': 34, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:14,718]\u001b[0m Trial 81 finished with value: 4.424638774176643 and parameters: {'n_estimators': 270, 'max_depth': 117, 'min_samples_split': 45, 'min_samples_leaf': 23}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:15,464]\u001b[0m Trial 82 finished with value: 4.413351331041891 and parameters: {'n_estimators': 292, 'max_depth': 98, 'min_samples_split': 13, 'min_samples_leaf': 26}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:15,626]\u001b[0m Trial 83 finished with value: 4.345627456152428 and parameters: {'n_estimators': 60, 'max_depth': 179, 'min_samples_split': 51, 'min_samples_leaf': 25}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:16,396]\u001b[0m Trial 84 finished with value: 4.334337661260529 and parameters: {'n_estimators': 267, 'max_depth': 96, 'min_samples_split': 39, 'min_samples_leaf': 9}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:17,633]\u001b[0m Trial 85 finished with value: 4.356908627934787 and parameters: {'n_estimators': 381, 'max_depth': 51, 'min_samples_split': 30, 'min_samples_leaf': 2}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:19,945]\u001b[0m Trial 86 finished with value: 4.345624843088931 and parameters: {'n_estimators': 820, 'max_depth': 20, 'min_samples_split': 34, 'min_samples_leaf': 10}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:21,796]\u001b[0m Trial 87 finished with value: 4.345621446106384 and parameters: {'n_estimators': 592, 'max_depth': 246, 'min_samples_split': 42, 'min_samples_leaf': 2}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:22,951]\u001b[0m Trial 88 finished with value: 4.402063887907139 and parameters: {'n_estimators': 442, 'max_depth': 131, 'min_samples_split': 35, 'min_samples_leaf': 22}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:23,661]\u001b[0m Trial 89 finished with value: 4.334340013017677 and parameters: {'n_estimators': 285, 'max_depth': 33, 'min_samples_split': 26, 'min_samples_leaf': 31}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:24,193]\u001b[0m Trial 90 finished with value: 4.3456264109270295 and parameters: {'n_estimators': 193, 'max_depth': 232, 'min_samples_split': 36, 'min_samples_leaf': 15}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:26,674]\u001b[0m Trial 91 finished with value: 4.356912808836382 and parameters: {'n_estimators': 904, 'max_depth': 118, 'min_samples_split': 47, 'min_samples_leaf': 13}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:29,268]\u001b[0m Trial 92 finished with value: 4.356912286223682 and parameters: {'n_estimators': 926, 'max_depth': 177, 'min_samples_split': 46, 'min_samples_leaf': 11}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:31,669]\u001b[0m Trial 93 finished with value: 4.289186320883422 and parameters: {'n_estimators': 776, 'max_depth': 163, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:33,827]\u001b[0m Trial 94 finished with value: 4.413351069735541 and parameters: {'n_estimators': 816, 'max_depth': 246, 'min_samples_split': 30, 'min_samples_leaf': 19}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:36,124]\u001b[0m Trial 95 finished with value: 4.379488740331285 and parameters: {'n_estimators': 879, 'max_depth': 118, 'min_samples_split': 61, 'min_samples_leaf': 19}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:38,551]\u001b[0m Trial 96 finished with value: 4.289187104802472 and parameters: {'n_estimators': 841, 'max_depth': 233, 'min_samples_split': 53, 'min_samples_leaf': 6}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:40,315]\u001b[0m Trial 97 finished with value: 4.356913070142732 and parameters: {'n_estimators': 645, 'max_depth': 102, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:40,984]\u001b[0m Trial 98 finished with value: 4.334340535630376 and parameters: {'n_estimators': 266, 'max_depth': 218, 'min_samples_split': 4, 'min_samples_leaf': 31}. Best is trial 61 with value: 4.2440373322634635.\u001b[0m\n",
      "\u001b[32m[I 2022-02-19 12:15:42,102]\u001b[0m Trial 99 finished with value: 4.232750411741411 and parameters: {'n_estimators': 365, 'max_depth': 92, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 99 with value: 4.232750411741411.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "etr = models.ERT({})\n",
    "optimized_params = beyesian_optimization(etr, X_train, y_train, {\n",
    "    'n_estimators': [2, 1024],\n",
    "    'max_depth': [1, 256],\n",
    "    'min_samples_split': [2, 64],\n",
    "    'min_samples_leaf': [1, 32],\n",
    "    'random_state': 0\n",
    "}, n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 365, 'max_depth': 92, 'min_samples_split': 3, 'min_samples_leaf': 6, 'random_state': 0}\n",
      "0.8795098039215686\n"
     ]
    }
   ],
   "source": [
    "print(optimized_params)\n",
    "print(cross_validation_score(models.ERT(optimized_params), X_train, y_train))\n",
    "with open('./config/ERT.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 12:15:48,289]\u001b[0m A new study created in memory with name: no-name-845ee65c-6467-437a-b655-d1a31f74981e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:15:48.302869: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-19 12:15:48.304517: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-19 12:15:48.305325: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:15:49.167902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.0835 - 3s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 2s - loss: 1.0685 - 2s/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.0329 - 1s/epoch - 26ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.0102 - 1s/epoch - 26ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 1.0015 - 1s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9824 - 1s/epoch - 24ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9795 - 1s/epoch - 24ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9820 - 1s/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9692 - 1s/epoch - 24ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9367 - 1s/epoch - 24ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.9455 - 1s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9331 - 1s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.9118 - 1s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.9156 - 1s/epoch - 24ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.9229 - 1s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8976 - 1s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8828 - 1s/epoch - 24ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8893 - 1s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8745 - 1s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8821 - 1s/epoch - 24ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8627 - 1s/epoch - 24ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8720 - 1s/epoch - 23ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8590 - 1s/epoch - 23ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8686 - 1s/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.8541 - 1s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8343 - 1s/epoch - 24ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.8470 - 1s/epoch - 23ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.8325 - 1s/epoch - 24ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8315 - 1s/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.8172 - 1s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8210 - 1s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.8226 - 1s/epoch - 23ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8284 - 1s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.8060 - 1s/epoch - 23ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7971 - 1s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.8144 - 1s/epoch - 23ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.8093 - 1s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.8049 - 1s/epoch - 24ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.8111 - 1s/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.7927 - 1s/epoch - 24ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7983 - 1s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7926 - 1s/epoch - 23ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7938 - 1s/epoch - 23ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7765 - 1s/epoch - 24ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7830 - 1s/epoch - 24ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7655 - 1s/epoch - 24ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7746 - 1s/epoch - 24ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7869 - 1s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 2s - loss: 0.7762 - 2s/epoch - 27ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 2s - loss: 0.7609 - 2s/epoch - 27ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7770 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7787 - 1s/epoch - 24ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7630 - 1s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7587 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7543 - 1s/epoch - 24ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7675 - 1s/epoch - 26ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7653 - 1s/epoch - 26ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7448 - 1s/epoch - 26ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 2s - loss: 0.7628 - 2s/epoch - 27ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 2s - loss: 0.7510 - 2s/epoch - 27ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7514 - 1s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 2s - loss: 0.7414 - 2s/epoch - 27ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7557 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.7470 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7393 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.7334 - 1s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7402 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.7332 - 1s/epoch - 24ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.7286 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7272 - 1s/epoch - 26ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7185 - 1s/epoch - 26ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7314 - 1s/epoch - 26ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 2s - loss: 0.7202 - 2s/epoch - 28ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 2s - loss: 0.7259 - 2s/epoch - 28ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 2s - loss: 0.7245 - 2s/epoch - 28ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7152 - 1s/epoch - 26ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.7185 - 1s/epoch - 26ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 2s - loss: 0.7150 - 2s/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 2s - loss: 0.7146 - 2s/epoch - 29ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7113 - 1s/epoch - 24ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.7170 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 2s - loss: 0.7137 - 2s/epoch - 30ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 2s - loss: 0.7231 - 2s/epoch - 28ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7004 - 1s/epoch - 27ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 2s - loss: 0.7081 - 2s/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 2s - loss: 0.7132 - 2s/epoch - 27ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7097 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7148 - 1s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7098 - 1s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7022 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7005 - 1s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7003 - 1s/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.6927 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7108 - 1s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7006 - 1s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.7023 - 1s/epoch - 24ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.6922 - 1s/epoch - 24ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7013 - 1s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.6908 - 1s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.6890 - 1s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:18:09.709521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:18:10,453]\u001b[0m Trial 0 finished with value: 26.1755806294897 and parameters: {'dropout': 0.49393666539955305}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:18:11.016817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.1054 - 3s/epoch - 49ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0907 - 1s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.0266 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.0372 - 1s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 1.0276 - 1s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9953 - 1s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9944 - 1s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9796 - 1s/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9806 - 1s/epoch - 24ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9829 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.9670 - 1s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9791 - 1s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.9519 - 1s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.9455 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.9455 - 1s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.9333 - 1s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.9506 - 1s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.9275 - 1s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.9151 - 1s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 2s - loss: 0.9403 - 2s/epoch - 29ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.9030 - 1s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.9069 - 1s/epoch - 24ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 2s - loss: 0.9015 - 2s/epoch - 27ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.9057 - 1s/epoch - 26ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 2s - loss: 0.9005 - 2s/epoch - 27ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 2s - loss: 0.8668 - 2s/epoch - 27ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.8980 - 1s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.8934 - 1s/epoch - 26ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 2s - loss: 0.8741 - 2s/epoch - 27ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.8584 - 1s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8938 - 1s/epoch - 26ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.8564 - 1s/epoch - 27ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8788 - 1s/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 2s - loss: 0.8654 - 2s/epoch - 28ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.8579 - 1s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 2s - loss: 0.8515 - 2s/epoch - 28ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.8742 - 1s/epoch - 26ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.8588 - 1s/epoch - 26ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.8451 - 1s/epoch - 26ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.8361 - 1s/epoch - 24ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.8513 - 1s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.8273 - 1s/epoch - 26ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.8466 - 1s/epoch - 24ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.8430 - 1s/epoch - 24ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.8697 - 1s/epoch - 24ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.8163 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.8251 - 1s/epoch - 24ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.8270 - 1s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.8167 - 1s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.8242 - 1s/epoch - 24ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.8265 - 1s/epoch - 24ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.8158 - 1s/epoch - 24ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.8155 - 1s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.8289 - 1s/epoch - 24ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.8025 - 1s/epoch - 24ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.8217 - 1s/epoch - 24ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7995 - 1s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.8047 - 1s/epoch - 24ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.8017 - 1s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.7990 - 1s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7957 - 1s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.8143 - 1s/epoch - 24ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7892 - 1s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.8143 - 1s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.8012 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.8147 - 1s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7830 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.8031 - 1s/epoch - 24ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.8010 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7967 - 1s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7749 - 1s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7829 - 1s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.8133 - 1s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7817 - 1s/epoch - 24ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.7707 - 1s/epoch - 24ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7770 - 1s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.7923 - 1s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7687 - 1s/epoch - 27ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.7793 - 1s/epoch - 26ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7699 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.7794 - 1s/epoch - 24ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.7570 - 1s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7815 - 1s/epoch - 24ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7648 - 1s/epoch - 24ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.7497 - 1s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.7789 - 1s/epoch - 24ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7664 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7563 - 1s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7774 - 1s/epoch - 24ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7765 - 1s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7506 - 1s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7611 - 1s/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.7688 - 1s/epoch - 24ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7596 - 1s/epoch - 27ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7487 - 1s/epoch - 26ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.7760 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.7566 - 1s/epoch - 24ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7476 - 1s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.7459 - 1s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7497 - 1s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:20:31.340996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:20:32,099]\u001b[0m Trial 1 finished with value: 26.1755806294897 and parameters: {'dropout': 0.6436732778415138}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:20:32.661158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.0417 - 3s/epoch - 52ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0214 - 1s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.0021 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.0170 - 1s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9707 - 1s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9506 - 1s/epoch - 24ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9636 - 1s/epoch - 24ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9255 - 1s/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9438 - 1s/epoch - 24ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9179 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.9116 - 1s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9012 - 1s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.9041 - 1s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8805 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.9060 - 1s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 2s - loss: 0.8785 - 2s/epoch - 29ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8873 - 1s/epoch - 26ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8717 - 1s/epoch - 27ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 2s - loss: 0.8933 - 2s/epoch - 28ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 2s - loss: 0.8563 - 2s/epoch - 27ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8629 - 1s/epoch - 26ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8641 - 1s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8258 - 1s/epoch - 24ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8474 - 1s/epoch - 26ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 2s - loss: 0.8635 - 2s/epoch - 29ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 2s - loss: 0.8451 - 2s/epoch - 27ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 2s - loss: 0.8481 - 2s/epoch - 27ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.8478 - 1s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8166 - 1s/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.8324 - 1s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8531 - 1s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.8403 - 1s/epoch - 24ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8022 - 1s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.8257 - 1s/epoch - 24ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.8078 - 1s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.8133 - 1s/epoch - 24ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.8246 - 1s/epoch - 24ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.8140 - 1s/epoch - 24ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.8108 - 1s/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.8091 - 1s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.8098 - 1s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.8158 - 1s/epoch - 27ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 2s - loss: 0.7871 - 2s/epoch - 27ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 2s - loss: 0.8100 - 2s/epoch - 27ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7953 - 1s/epoch - 26ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7982 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7830 - 1s/epoch - 24ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7756 - 1s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.7956 - 1s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.7930 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7753 - 1s/epoch - 26ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 2s - loss: 0.7887 - 2s/epoch - 27ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7772 - 1s/epoch - 27ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7783 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7594 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7749 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7722 - 1s/epoch - 27ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7730 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.7668 - 1s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.7756 - 1s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7496 - 1s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.7654 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7519 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.7572 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7861 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.7567 - 1s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7665 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.7569 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.7584 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7541 - 1s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7585 - 1s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7482 - 1s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.7571 - 1s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7377 - 1s/epoch - 26ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.7578 - 1s/epoch - 26ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7521 - 1s/epoch - 26ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 2s - loss: 0.7502 - 2s/epoch - 27ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7505 - 1s/epoch - 26ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 2s - loss: 0.7402 - 2s/epoch - 27ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7468 - 1s/epoch - 26ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 2s - loss: 0.7194 - 2s/epoch - 27ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 2s - loss: 0.7297 - 2s/epoch - 27ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7432 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7442 - 1s/epoch - 26ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 2s - loss: 0.7487 - 2s/epoch - 30ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 2s - loss: 0.7446 - 2s/epoch - 28ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7372 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7434 - 1s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7345 - 1s/epoch - 26ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7276 - 1s/epoch - 26ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 2s - loss: 0.7346 - 2s/epoch - 27ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7261 - 1s/epoch - 26ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.7190 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7264 - 1s/epoch - 26ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7262 - 1s/epoch - 26ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 2s - loss: 0.7220 - 2s/epoch - 28ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.7278 - 1s/epoch - 26ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7161 - 1s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.7280 - 1s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7216 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:22:56.367635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:22:57,207]\u001b[0m Trial 2 finished with value: 26.1755806294897 and parameters: {'dropout': 0.5424910108307187}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:22:57.812303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.0269 - 3s/epoch - 57ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0216 - 1s/epoch - 26ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 0.9773 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 0.9607 - 1s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9616 - 1s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9351 - 1s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9287 - 1s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.8885 - 1s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9084 - 1s/epoch - 26ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.8970 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.8850 - 1s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.8861 - 1s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.8773 - 1s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8940 - 1s/epoch - 24ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8815 - 1s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8692 - 1s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8629 - 1s/epoch - 24ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8368 - 1s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8489 - 1s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8462 - 1s/epoch - 24ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8367 - 1s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8321 - 1s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8358 - 1s/epoch - 26ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 2s - loss: 0.8343 - 2s/epoch - 28ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 2s - loss: 0.8398 - 2s/epoch - 27ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8202 - 1s/epoch - 27ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.8314 - 1s/epoch - 26ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 2s - loss: 0.8158 - 2s/epoch - 30ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8019 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 2s - loss: 0.8184 - 2s/epoch - 27ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8048 - 1s/epoch - 27ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 2s - loss: 0.8091 - 2s/epoch - 27ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8063 - 1s/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 2s - loss: 0.7918 - 2s/epoch - 27ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7882 - 1s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 2s - loss: 0.7863 - 2s/epoch - 27ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 2s - loss: 0.8007 - 2s/epoch - 27ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 2s - loss: 0.7832 - 2s/epoch - 28ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 2s - loss: 0.7905 - 2s/epoch - 27ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 2s - loss: 0.7799 - 2s/epoch - 27ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7644 - 1s/epoch - 26ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7872 - 1s/epoch - 26ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7770 - 1s/epoch - 26ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7775 - 1s/epoch - 26ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 2s - loss: 0.7618 - 2s/epoch - 27ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7614 - 1s/epoch - 26ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7617 - 1s/epoch - 26ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7744 - 1s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.7727 - 1s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 2s - loss: 0.7370 - 2s/epoch - 27ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 2s - loss: 0.7747 - 2s/epoch - 27ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7438 - 1s/epoch - 26ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7577 - 1s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7362 - 1s/epoch - 24ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7574 - 1s/epoch - 24ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7326 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7646 - 1s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7471 - 1s/epoch - 24ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.7301 - 1s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.7315 - 1s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7357 - 1s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.7214 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7385 - 1s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.7188 - 1s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7179 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.7338 - 1s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7233 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.7173 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.7367 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7317 - 1s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7168 - 1s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7242 - 1s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.7234 - 1s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7103 - 1s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.7112 - 1s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7264 - 1s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.7251 - 1s/epoch - 24ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7249 - 1s/epoch - 24ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.7143 - 1s/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7080 - 1s/epoch - 24ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.7124 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.7119 - 1s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7273 - 1s/epoch - 24ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7064 - 1s/epoch - 24ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.6937 - 1s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.7159 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7011 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.6986 - 1s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.6990 - 1s/epoch - 24ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.6981 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7110 - 1s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.6956 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.6976 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7042 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.6978 - 1s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.6977 - 1s/epoch - 24ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.6952 - 1s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.6911 - 1s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.6890 - 1s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7098 - 1s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:25:20.405812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:25:21,259]\u001b[0m Trial 3 finished with value: 26.1755806294897 and parameters: {'dropout': 0.4903994158653773}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:25:21.812168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 4s - loss: 1.1067 - 4s/epoch - 63ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 2s - loss: 1.0534 - 2s/epoch - 28ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 2s - loss: 1.0332 - 2s/epoch - 27ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.0087 - 1s/epoch - 26ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 2s - loss: 1.0001 - 2s/epoch - 27ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9713 - 1s/epoch - 26ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 2s - loss: 0.9607 - 2s/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9426 - 1s/epoch - 26ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9371 - 1s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9344 - 1s/epoch - 26ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.9268 - 1s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9079 - 1s/epoch - 26ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.8890 - 1s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8979 - 1s/epoch - 26ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8766 - 1s/epoch - 26ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8481 - 1s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8747 - 1s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8485 - 1s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8347 - 1s/epoch - 26ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 2s - loss: 0.8704 - 2s/epoch - 28ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8448 - 1s/epoch - 26ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 2s - loss: 0.8316 - 2s/epoch - 27ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8160 - 1s/epoch - 26ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8237 - 1s/epoch - 27ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.8004 - 1s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8018 - 1s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.7991 - 1s/epoch - 26ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.7960 - 1s/epoch - 26ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8090 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.7795 - 1s/epoch - 26ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.7946 - 1s/epoch - 26ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.7674 - 1s/epoch - 26ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.7883 - 1s/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.7702 - 1s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7708 - 1s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.7715 - 1s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.7670 - 1s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.7558 - 1s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 2s - loss: 0.7683 - 2s/epoch - 30ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.7497 - 1s/epoch - 26ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 2s - loss: 0.7475 - 2s/epoch - 27ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 2s - loss: 0.7613 - 2s/epoch - 27ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7494 - 1s/epoch - 26ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7371 - 1s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7408 - 1s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 2s - loss: 0.7319 - 2s/epoch - 28ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7349 - 1s/epoch - 26ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7300 - 1s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.7224 - 1s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.7331 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7106 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7258 - 1s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7193 - 1s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7116 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7159 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7111 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7008 - 1s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7119 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.6978 - 1s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.6971 - 1s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.6843 - 1s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.6973 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.6938 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.6948 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.6988 - 1s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.6921 - 1s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.6952 - 1s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.6964 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.6639 - 1s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.6897 - 1s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.6830 - 1s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.6774 - 1s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.6819 - 1s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.6801 - 1s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.6754 - 1s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.6747 - 1s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.6652 - 1s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.6724 - 1s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.6698 - 1s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.6648 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.6645 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.6601 - 1s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.6619 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.6511 - 1s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.6532 - 1s/epoch - 26ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.6618 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.6523 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.6447 - 1s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.6437 - 1s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.6611 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.6621 - 1s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.6458 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.6424 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.6549 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.6442 - 1s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.6406 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.6379 - 1s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.6555 - 1s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.6530 - 1s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.6448 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:27:46.163488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:27:47,059]\u001b[0m Trial 4 finished with value: 26.1755806294897 and parameters: {'dropout': 0.3812950828570209}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:27:48.922981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.0827 - 3s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0456 - 1s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.0296 - 1s/epoch - 24ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.0128 - 1s/epoch - 24ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9946 - 1s/epoch - 24ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 1.0010 - 1s/epoch - 24ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9720 - 1s/epoch - 24ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9762 - 1s/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9602 - 1s/epoch - 24ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9439 - 1s/epoch - 24ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.9322 - 1s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9228 - 1s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.9308 - 1s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.9022 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8872 - 1s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.9223 - 1s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8892 - 1s/epoch - 24ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8920 - 1s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.9063 - 1s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8901 - 1s/epoch - 24ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8662 - 1s/epoch - 24ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8752 - 1s/epoch - 24ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8740 - 1s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8573 - 1s/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.8636 - 1s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8267 - 1s/epoch - 24ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.8475 - 1s/epoch - 24ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.8517 - 1s/epoch - 24ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8291 - 1s/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.8377 - 1s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8461 - 1s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.8416 - 1s/epoch - 24ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8170 - 1s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.8163 - 1s/epoch - 24ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.8119 - 1s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.8260 - 1s/epoch - 24ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.8041 - 1s/epoch - 24ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.8048 - 1s/epoch - 24ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.8010 - 1s/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.8230 - 1s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7929 - 1s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7885 - 1s/epoch - 24ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.8158 - 1s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7888 - 1s/epoch - 26ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.8067 - 1s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7939 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7821 - 1s/epoch - 26ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7806 - 1s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.8047 - 1s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.7763 - 1s/epoch - 24ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7779 - 1s/epoch - 24ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7876 - 1s/epoch - 24ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7814 - 1s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7779 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7673 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7804 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7823 - 1s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7722 - 1s/epoch - 24ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.7630 - 1s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.7594 - 1s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7603 - 1s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.7624 - 1s/epoch - 24ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7649 - 1s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.7651 - 1s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7554 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.7602 - 1s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7489 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.7485 - 1s/epoch - 24ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.7480 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7401 - 1s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7537 - 1s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7398 - 1s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.7464 - 1s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7451 - 1s/epoch - 24ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.7399 - 1s/epoch - 24ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7390 - 1s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.7380 - 1s/epoch - 24ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7252 - 1s/epoch - 24ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.7220 - 1s/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7333 - 1s/epoch - 24ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.7433 - 1s/epoch - 24ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.7243 - 1s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7269 - 1s/epoch - 24ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7109 - 1s/epoch - 24ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.7264 - 1s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.7196 - 1s/epoch - 24ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7214 - 1s/epoch - 24ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7206 - 1s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7064 - 1s/epoch - 24ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7197 - 1s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7238 - 1s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7185 - 1s/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.7206 - 1s/epoch - 24ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7234 - 1s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7135 - 1s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.7040 - 1s/epoch - 24ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.7052 - 1s/epoch - 24ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7172 - 1s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.7099 - 1s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7060 - 1s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:30:05.658248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:30:06,507]\u001b[0m Trial 5 finished with value: 26.1755806294897 and parameters: {'dropout': 0.5813082428188598}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:30:07.090832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.0649 - 3s/epoch - 57ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0205 - 1s/epoch - 26ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 0.9879 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 0.9665 - 1s/epoch - 24ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9678 - 1s/epoch - 24ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9392 - 1s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9412 - 1s/epoch - 24ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9142 - 1s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9060 - 1s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.8995 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.8836 - 1s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.8787 - 1s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.8702 - 1s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8641 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8538 - 1s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8608 - 1s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8456 - 1s/epoch - 24ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8332 - 1s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8338 - 1s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8183 - 1s/epoch - 24ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8175 - 1s/epoch - 24ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8220 - 1s/epoch - 24ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8065 - 1s/epoch - 24ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8137 - 1s/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.7962 - 1s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8115 - 1s/epoch - 24ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.7761 - 1s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.7807 - 1s/epoch - 24ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.7782 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.7534 - 1s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.7806 - 1s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.7709 - 1s/epoch - 24ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.7711 - 1s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.7652 - 1s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7540 - 1s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.7557 - 1s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.7687 - 1s/epoch - 24ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.7568 - 1s/epoch - 24ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.7447 - 1s/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.7490 - 1s/epoch - 24ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7379 - 1s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7407 - 1s/epoch - 24ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7489 - 1s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7263 - 1s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7375 - 1s/epoch - 24ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7166 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7279 - 1s/epoch - 24ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7238 - 1s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.7241 - 1s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.7169 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7090 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7201 - 1s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.6973 - 1s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7223 - 1s/epoch - 24ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7007 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7046 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.6990 - 1s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7061 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.7002 - 1s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.6972 - 1s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.6995 - 1s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.7055 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.6953 - 1s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.6915 - 1s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7002 - 1s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.6933 - 1s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.6877 - 1s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.6770 - 1s/epoch - 24ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.6791 - 1s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.6869 - 1s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.6984 - 1s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.6843 - 1s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.6701 - 1s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.6817 - 1s/epoch - 24ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.6685 - 1s/epoch - 24ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.6728 - 1s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.6785 - 1s/epoch - 24ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.6550 - 1s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.6754 - 1s/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.6716 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.6756 - 1s/epoch - 24ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.6671 - 1s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.6743 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.6490 - 1s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.6618 - 1s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.6590 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.6587 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.6644 - 1s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.6679 - 1s/epoch - 24ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.6596 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.6535 - 1s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.6514 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.6500 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.6668 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.6476 - 1s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.6531 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.6522 - 1s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.6467 - 1s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.6485 - 1s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.6524 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:32:25.980112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:32:26,811]\u001b[0m Trial 6 finished with value: 26.1755806294897 and parameters: {'dropout': 0.3938341142643107}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:32:27.383081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 3s - loss: 1.2712 - 3s/epoch - 58ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.1681 - 1s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.1510 - 1s/epoch - 26ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 1.1279 - 1s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 1.1173 - 1s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 1.0847 - 1s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 1.0627 - 1s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 1.0483 - 1s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9869 - 1s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 1.0326 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 1.0341 - 1s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 1.0143 - 1s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.9698 - 1s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.9946 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.9753 - 1s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.9852 - 1s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.9718 - 1s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.9743 - 1s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.9604 - 1s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.9649 - 1s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.9569 - 1s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.9349 - 1s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.9452 - 1s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.9161 - 1s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.9187 - 1s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.9406 - 1s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.9103 - 1s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.8974 - 1s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8986 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.9270 - 1s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8957 - 1s/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.9212 - 1s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.9047 - 1s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.9151 - 1s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.9064 - 1s/epoch - 26ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.9000 - 1s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.9164 - 1s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.8510 - 1s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.8871 - 1s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.8736 - 1s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.8702 - 1s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.8724 - 1s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.8614 - 1s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.8550 - 1s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.8368 - 1s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.8815 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.8321 - 1s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.8313 - 1s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.8826 - 1s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.8659 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.8572 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.8294 - 1s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.8385 - 1s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.8417 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.8749 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.8362 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.8684 - 1s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.8414 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.8217 - 1s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.8385 - 1s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.8084 - 1s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.8373 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.8160 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.8142 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.8200 - 1s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.8120 - 1s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.8121 - 1s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.8219 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.8082 - 1s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.8126 - 1s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.8026 - 1s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.8403 - 1s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.8164 - 1s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7867 - 1s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.8161 - 1s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7988 - 1s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.8041 - 1s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7866 - 1s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.7890 - 1s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.8345 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.8136 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.7815 - 1s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7816 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7670 - 1s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.7884 - 1s/epoch - 25ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.7747 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.8200 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7900 - 1s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7814 - 1s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7754 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7794 - 1s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7607 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.7733 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7642 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7875 - 1s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.7663 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.7850 - 1s/epoch - 26ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7606 - 1s/epoch - 26ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.7603 - 1s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7748 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:34:48.455045: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:34:49,406]\u001b[0m Trial 7 finished with value: 26.1755806294897 and parameters: {'dropout': 0.8025967829738639}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:34:49.972087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 4s - loss: 0.9791 - 4s/epoch - 64ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 2s - loss: 0.9816 - 2s/epoch - 28ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 0.9687 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 0.9346 - 1s/epoch - 26ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9428 - 1s/epoch - 26ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9109 - 1s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.8861 - 1s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.8849 - 1s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9036 - 1s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.8529 - 1s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.8666 - 1s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.9079 - 1s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.8620 - 1s/epoch - 26ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8684 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8158 - 1s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8497 - 1s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8246 - 1s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8084 - 1s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8341 - 1s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8439 - 1s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.8714 - 1s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8206 - 1s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8583 - 1s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8328 - 1s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.8245 - 1s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.8316 - 1s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.8217 - 1s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.7957 - 1s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.8264 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.8016 - 1s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.8395 - 1s/epoch - 26ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.8031 - 1s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.8176 - 1s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.7798 - 1s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7968 - 1s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.7583 - 1s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.8099 - 1s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.7930 - 1s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.7823 - 1s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.7851 - 1s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7925 - 1s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7954 - 1s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7927 - 1s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7923 - 1s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7708 - 1s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.7503 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.7829 - 1s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.7885 - 1s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.7773 - 1s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.7926 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.7931 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.7662 - 1s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.7588 - 1s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.7767 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.7749 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.7636 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.7634 - 1s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.7413 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.7684 - 1s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.7418 - 1s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.7541 - 1s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.7731 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.7563 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.7584 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.7613 - 1s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.7324 - 1s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.7559 - 1s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.7504 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.7443 - 1s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.7703 - 1s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.7918 - 1s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.7303 - 1s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.7573 - 1s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.7316 - 1s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.7454 - 1s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.7459 - 1s/epoch - 26ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.7449 - 1s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.7360 - 1s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.7221 - 1s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.7522 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.7329 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.7589 - 1s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.7197 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.7366 - 1s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.7218 - 1s/epoch - 25ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.7224 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.7210 - 1s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.7368 - 1s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.7423 - 1s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.7420 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.7284 - 1s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.7476 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.7409 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.7126 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.7205 - 1s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.7210 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.7251 - 1s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.7234 - 1s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.7460 - 1s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.7478 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:37:12.827039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:37:13,697]\u001b[0m Trial 8 finished with value: 26.1755806294897 and parameters: {'dropout': 0.8672968478233214}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:37:14.267949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 4s - loss: 1.1061 - 4s/epoch - 64ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 1s - loss: 1.0369 - 1s/epoch - 26ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 1s - loss: 1.0166 - 1s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 1s - loss: 0.9773 - 1s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 1s - loss: 0.9602 - 1s/epoch - 26ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 1s - loss: 0.9548 - 1s/epoch - 26ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 1s - loss: 0.9352 - 1s/epoch - 26ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 1s - loss: 0.9053 - 1s/epoch - 26ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 1s - loss: 0.9037 - 1s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 1s - loss: 0.9191 - 1s/epoch - 26ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 1s - loss: 0.8726 - 1s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 1s - loss: 0.8745 - 1s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 1s - loss: 0.8724 - 1s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 1s - loss: 0.8605 - 1s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 1s - loss: 0.8464 - 1s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 1s - loss: 0.8521 - 1s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 1s - loss: 0.8522 - 1s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 1s - loss: 0.8304 - 1s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 1s - loss: 0.8192 - 1s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 1s - loss: 0.8238 - 1s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 1s - loss: 0.7972 - 1s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 1s - loss: 0.8120 - 1s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 1s - loss: 0.8083 - 1s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 1s - loss: 0.8024 - 1s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 1s - loss: 0.7866 - 1s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 1s - loss: 0.7737 - 1s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 1s - loss: 0.7721 - 1s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 1s - loss: 0.7848 - 1s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 1s - loss: 0.7782 - 1s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 1s - loss: 0.7632 - 1s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 1s - loss: 0.7520 - 1s/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 1s - loss: 0.7403 - 1s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 1s - loss: 0.7537 - 1s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 1s - loss: 0.7602 - 1s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 1s - loss: 0.7301 - 1s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 1s - loss: 0.7431 - 1s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 1s - loss: 0.7260 - 1s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 1s - loss: 0.7192 - 1s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 1s - loss: 0.7274 - 1s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 1s - loss: 0.7102 - 1s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 1s - loss: 0.7180 - 1s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 1s - loss: 0.7215 - 1s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 1s - loss: 0.7189 - 1s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 1s - loss: 0.7123 - 1s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 1s - loss: 0.7094 - 1s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 1s - loss: 0.6933 - 1s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 1s - loss: 0.6967 - 1s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 1s - loss: 0.6812 - 1s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 1s - loss: 0.6980 - 1s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 1s - loss: 0.6893 - 1s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 1s - loss: 0.6796 - 1s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 1s - loss: 0.6825 - 1s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 1s - loss: 0.6781 - 1s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 1s - loss: 0.6656 - 1s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 1s - loss: 0.6735 - 1s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 1s - loss: 0.6754 - 1s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 1s - loss: 0.6722 - 1s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 1s - loss: 0.6655 - 1s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 1s - loss: 0.6740 - 1s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 1s - loss: 0.6659 - 1s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 1s - loss: 0.6607 - 1s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 1s - loss: 0.6685 - 1s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 1s - loss: 0.6634 - 1s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 1s - loss: 0.6571 - 1s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 1s - loss: 0.6673 - 1s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 1s - loss: 0.6561 - 1s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 1s - loss: 0.6361 - 1s/epoch - 26ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 1s - loss: 0.6583 - 1s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 1s - loss: 0.6497 - 1s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 1s - loss: 0.6360 - 1s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 1s - loss: 0.6485 - 1s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 1s - loss: 0.6396 - 1s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 1s - loss: 0.6307 - 1s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 1s - loss: 0.6330 - 1s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 1s - loss: 0.6381 - 1s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 1s - loss: 0.6260 - 1s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 1s - loss: 0.6310 - 1s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 1s - loss: 0.6355 - 1s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 1s - loss: 0.6211 - 1s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 1s - loss: 0.6232 - 1s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 1s - loss: 0.6177 - 1s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 1s - loss: 0.6240 - 1s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 1s - loss: 0.6261 - 1s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 1s - loss: 0.6221 - 1s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 1s - loss: 0.6274 - 1s/epoch - 25ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 1s - loss: 0.6242 - 1s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 1s - loss: 0.6116 - 1s/epoch - 26ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 1s - loss: 0.6178 - 1s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 1s - loss: 0.6211 - 1s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 1s - loss: 0.6202 - 1s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 1s - loss: 0.6077 - 1s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 1s - loss: 0.6084 - 1s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 1s - loss: 0.6027 - 1s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "56/56 - 1s - loss: 0.5986 - 1s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "56/56 - 1s - loss: 0.6099 - 1s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "56/56 - 1s - loss: 0.6133 - 1s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "56/56 - 1s - loss: 0.5997 - 1s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "56/56 - 1s - loss: 0.6030 - 1s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "56/56 - 1s - loss: 0.6032 - 1s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "56/56 - 1s - loss: 0.5995 - 1s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:39:37.168826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2022-02-19 12:39:38,050]\u001b[0m Trial 9 finished with value: 26.1755806294897 and parameters: {'dropout': 0.34510353252801174}. Best is trial 0 with value: 26.1755806294897.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# nn = models.NN({})\n",
    "# optimized_params = beyesian_optimization(nn, X_train, y_train, {\n",
    "#     'layers': 4,\n",
    "#     'dropout': [0.00001, 0.9],\n",
    "#     'units': 10,\n",
    "#     'nb_epoch': 100,\n",
    "# }, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': 4, 'dropout': 0.49393666539955305, 'units': 10, 'nb_epoch': 100}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:39:40.638161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 5s - loss: 1.0436 - 5s/epoch - 80ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 2s - loss: 1.0169 - 2s/epoch - 26ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 2s - loss: 0.9979 - 2s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 2s - loss: 0.9852 - 2s/epoch - 26ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 2s - loss: 0.9528 - 2s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 2s - loss: 0.9532 - 2s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 2s - loss: 0.9221 - 2s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 2s - loss: 0.9228 - 2s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 2s - loss: 0.9105 - 2s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 2s - loss: 0.8864 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 2s - loss: 0.8940 - 2s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 2s - loss: 0.8722 - 2s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 2s - loss: 0.8838 - 2s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 2s - loss: 0.8776 - 2s/epoch - 24ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 2s - loss: 0.8605 - 2s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 2s - loss: 0.8775 - 2s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 2s - loss: 0.8696 - 2s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 2s - loss: 0.8553 - 2s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 2s - loss: 0.8296 - 2s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 2s - loss: 0.8398 - 2s/epoch - 24ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 2s - loss: 0.8279 - 2s/epoch - 24ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 2s - loss: 0.8294 - 2s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 2s - loss: 0.8125 - 2s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 2s - loss: 0.8261 - 2s/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 2s - loss: 0.8288 - 2s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 2s - loss: 0.8228 - 2s/epoch - 24ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 2s - loss: 0.8250 - 2s/epoch - 24ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 2s - loss: 0.7955 - 2s/epoch - 24ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 2s - loss: 0.7966 - 2s/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 2s - loss: 0.8116 - 2s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 2s - loss: 0.7879 - 2s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 2s - loss: 0.8009 - 2s/epoch - 24ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 2s - loss: 0.7771 - 2s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 2s - loss: 0.8060 - 2s/epoch - 24ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 2s - loss: 0.7836 - 2s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 2s - loss: 0.7807 - 2s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 2s - loss: 0.7690 - 2s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 2s - loss: 0.7659 - 2s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 2s - loss: 0.7665 - 2s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 2s - loss: 0.7768 - 2s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 2s - loss: 0.7756 - 2s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 2s - loss: 0.7579 - 2s/epoch - 24ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 2s - loss: 0.7804 - 2s/epoch - 24ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 2s - loss: 0.7522 - 2s/epoch - 24ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 2s - loss: 0.7667 - 2s/epoch - 24ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 2s - loss: 0.7716 - 2s/epoch - 24ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 2s - loss: 0.7550 - 2s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 2s - loss: 0.7541 - 2s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 2s - loss: 0.7451 - 2s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 2s - loss: 0.7487 - 2s/epoch - 24ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 2s - loss: 0.7303 - 2s/epoch - 24ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 2s - loss: 0.7421 - 2s/epoch - 24ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 2s - loss: 0.7434 - 2s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 2s - loss: 0.7382 - 2s/epoch - 24ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 2s - loss: 0.7328 - 2s/epoch - 24ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 2s - loss: 0.7201 - 2s/epoch - 24ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 2s - loss: 0.7288 - 2s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 2s - loss: 0.7361 - 2s/epoch - 24ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 2s - loss: 0.7450 - 2s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 2s - loss: 0.7379 - 2s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 2s - loss: 0.7370 - 2s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 2s - loss: 0.7262 - 2s/epoch - 24ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 2s - loss: 0.7321 - 2s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 2s - loss: 0.7332 - 2s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 2s - loss: 0.7185 - 2s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 2s - loss: 0.7157 - 2s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 2s - loss: 0.7222 - 2s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 2s - loss: 0.7283 - 2s/epoch - 24ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 2s - loss: 0.7108 - 2s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 2s - loss: 0.7245 - 2s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 2s - loss: 0.7197 - 2s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 2s - loss: 0.7153 - 2s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 2s - loss: 0.7284 - 2s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 2s - loss: 0.7187 - 2s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 2s - loss: 0.7085 - 2s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 2s - loss: 0.7211 - 2s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 2s - loss: 0.7021 - 2s/epoch - 24ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 2s - loss: 0.7042 - 2s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 2s - loss: 0.7041 - 2s/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 2s - loss: 0.7030 - 2s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 2s - loss: 0.7013 - 2s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 2s - loss: 0.7030 - 2s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 2s - loss: 0.6990 - 2s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 2s - loss: 0.7069 - 2s/epoch - 24ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 2s - loss: 0.6994 - 2s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 2s - loss: 0.6918 - 2s/epoch - 24ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 2s - loss: 0.6898 - 2s/epoch - 24ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 2s - loss: 0.6891 - 2s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 2s - loss: 0.6880 - 2s/epoch - 24ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 2s - loss: 0.7154 - 2s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 2s - loss: 0.6944 - 2s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 2s - loss: 0.6967 - 2s/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 2s - loss: 0.6834 - 2s/epoch - 24ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 2s - loss: 0.6950 - 2s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 2s - loss: 0.6804 - 2s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 2s - loss: 0.6852 - 2s/epoch - 24ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 2s - loss: 0.6891 - 2s/epoch - 24ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 2s - loss: 0.6769 - 2s/epoch - 24ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 2s - loss: 0.6782 - 2s/epoch - 24ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 2s - loss: 0.6929 - 2s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:42:18.874422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:42:20.079329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 3s - loss: 1.0938 - 3s/epoch - 51ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 2s - loss: 1.0729 - 2s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 2s - loss: 1.0401 - 2s/epoch - 24ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 2s - loss: 1.0282 - 2s/epoch - 24ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 2s - loss: 1.0146 - 2s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 2s - loss: 0.9787 - 2s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 2s - loss: 0.9781 - 2s/epoch - 24ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 2s - loss: 0.9678 - 2s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 2s - loss: 0.9592 - 2s/epoch - 24ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 2s - loss: 0.9609 - 2s/epoch - 24ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 2s - loss: 0.9170 - 2s/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 2s - loss: 0.9265 - 2s/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 2s - loss: 0.8933 - 2s/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 2s - loss: 0.8959 - 2s/epoch - 24ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 2s - loss: 0.9008 - 2s/epoch - 24ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 2s - loss: 0.8951 - 2s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 2s - loss: 0.8762 - 2s/epoch - 24ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 2s - loss: 0.8762 - 2s/epoch - 24ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 2s - loss: 0.8718 - 2s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 2s - loss: 0.8522 - 2s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 2s - loss: 0.8623 - 2s/epoch - 24ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 2s - loss: 0.8444 - 2s/epoch - 24ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 2s - loss: 0.8503 - 2s/epoch - 24ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 2s - loss: 0.8395 - 2s/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 2s - loss: 0.8383 - 2s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 2s - loss: 0.8350 - 2s/epoch - 24ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 2s - loss: 0.8458 - 2s/epoch - 24ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 2s - loss: 0.8200 - 2s/epoch - 24ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 2s - loss: 0.8243 - 2s/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 2s - loss: 0.8239 - 2s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 2s - loss: 0.8223 - 2s/epoch - 24ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 2s - loss: 0.8259 - 2s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 2s - loss: 0.7981 - 2s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 2s - loss: 0.7935 - 2s/epoch - 24ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 2s - loss: 0.8027 - 2s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 2s - loss: 0.8018 - 2s/epoch - 24ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 2s - loss: 0.7930 - 2s/epoch - 24ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 2s - loss: 0.7826 - 2s/epoch - 24ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 2s - loss: 0.7751 - 2s/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 2s - loss: 0.7873 - 2s/epoch - 24ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 2s - loss: 0.7783 - 2s/epoch - 24ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 2s - loss: 0.7839 - 2s/epoch - 24ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 2s - loss: 0.7683 - 2s/epoch - 24ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 2s - loss: 0.7553 - 2s/epoch - 24ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 2s - loss: 0.7628 - 2s/epoch - 24ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 2s - loss: 0.7673 - 2s/epoch - 24ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 2s - loss: 0.7534 - 2s/epoch - 24ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 2s - loss: 0.7462 - 2s/epoch - 24ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 2s - loss: 0.7441 - 2s/epoch - 24ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 2s - loss: 0.7684 - 2s/epoch - 24ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 2s - loss: 0.7555 - 2s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 2s - loss: 0.7468 - 2s/epoch - 24ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 2s - loss: 0.7658 - 2s/epoch - 24ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 2s - loss: 0.7420 - 2s/epoch - 24ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 2s - loss: 0.7591 - 2s/epoch - 24ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 2s - loss: 0.7497 - 2s/epoch - 24ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 2s - loss: 0.7364 - 2s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 2s - loss: 0.7386 - 2s/epoch - 24ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 2s - loss: 0.7381 - 2s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 2s - loss: 0.7266 - 2s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 2s - loss: 0.7311 - 2s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 2s - loss: 0.7314 - 2s/epoch - 24ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 2s - loss: 0.7201 - 2s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 2s - loss: 0.7176 - 2s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 2s - loss: 0.7247 - 2s/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 2s - loss: 0.7153 - 2s/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 2s - loss: 0.7197 - 2s/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 2s - loss: 0.7288 - 2s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 2s - loss: 0.7196 - 2s/epoch - 24ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 2s - loss: 0.7331 - 2s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 2s - loss: 0.7062 - 2s/epoch - 24ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 2s - loss: 0.7207 - 2s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 2s - loss: 0.7136 - 2s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 2s - loss: 0.7091 - 2s/epoch - 24ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 2s - loss: 0.7058 - 2s/epoch - 24ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 2s - loss: 0.7113 - 2s/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 2s - loss: 0.7061 - 2s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 2s - loss: 0.6969 - 2s/epoch - 24ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 2s - loss: 0.7031 - 2s/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 2s - loss: 0.7090 - 2s/epoch - 24ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 2s - loss: 0.7130 - 2s/epoch - 24ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 2s - loss: 0.6975 - 2s/epoch - 24ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 2s - loss: 0.6977 - 2s/epoch - 24ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 2s - loss: 0.6831 - 2s/epoch - 24ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 2s - loss: 0.6904 - 2s/epoch - 24ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 2s - loss: 0.7022 - 2s/epoch - 24ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 2s - loss: 0.6916 - 2s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 2s - loss: 0.6839 - 2s/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 2s - loss: 0.7010 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 2s - loss: 0.6831 - 2s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 2s - loss: 0.6903 - 2s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 2s - loss: 0.6945 - 2s/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 2s - loss: 0.6862 - 2s/epoch - 24ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 2s - loss: 0.6886 - 2s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 2s - loss: 0.6878 - 2s/epoch - 24ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 2s - loss: 0.6890 - 2s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 2s - loss: 0.6772 - 2s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 2s - loss: 0.6707 - 2s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 2s - loss: 0.6829 - 2s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 2s - loss: 0.6690 - 2s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:44:57.237337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:44:58.475796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 3s - loss: 1.0571 - 3s/epoch - 54ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 2s - loss: 1.0366 - 2s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 2s - loss: 1.0176 - 2s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 2s - loss: 0.9715 - 2s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 2s - loss: 0.9687 - 2s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 2s - loss: 0.9590 - 2s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 2s - loss: 0.9681 - 2s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 2s - loss: 0.9243 - 2s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 2s - loss: 0.9297 - 2s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 2s - loss: 0.9016 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 2s - loss: 0.9108 - 2s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 2s - loss: 0.9040 - 2s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 2s - loss: 0.8714 - 2s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 2s - loss: 0.8848 - 2s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 2s - loss: 0.8963 - 2s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 2s - loss: 0.8630 - 2s/epoch - 24ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 2s - loss: 0.8640 - 2s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 2s - loss: 0.8384 - 2s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 2s - loss: 0.8635 - 2s/epoch - 24ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 2s - loss: 0.8489 - 2s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 2s - loss: 0.8504 - 2s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 2s - loss: 0.8345 - 2s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 2s - loss: 0.8279 - 2s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 2s - loss: 0.8306 - 2s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 2s - loss: 0.8151 - 2s/epoch - 24ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 2s - loss: 0.8109 - 2s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 2s - loss: 0.8257 - 2s/epoch - 24ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 2s - loss: 0.8095 - 2s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 2s - loss: 0.7958 - 2s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 2s - loss: 0.8137 - 2s/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 2s - loss: 0.8030 - 2s/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 2s - loss: 0.7870 - 2s/epoch - 24ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 2s - loss: 0.8037 - 2s/epoch - 24ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 2s - loss: 0.8024 - 2s/epoch - 24ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 2s - loss: 0.7932 - 2s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 2s - loss: 0.7752 - 2s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 2s - loss: 0.7741 - 2s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 2s - loss: 0.7753 - 2s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 2s - loss: 0.7564 - 2s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 2s - loss: 0.7877 - 2s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 2s - loss: 0.7702 - 2s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 2s - loss: 0.7692 - 2s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 2s - loss: 0.7552 - 2s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 2s - loss: 0.7628 - 2s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 2s - loss: 0.7690 - 2s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 2s - loss: 0.7509 - 2s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 2s - loss: 0.7576 - 2s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 2s - loss: 0.7542 - 2s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 2s - loss: 0.7476 - 2s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 2s - loss: 0.7386 - 2s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 2s - loss: 0.7577 - 2s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 2s - loss: 0.7428 - 2s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 2s - loss: 0.7421 - 2s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 2s - loss: 0.7363 - 2s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 2s - loss: 0.7459 - 2s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 2s - loss: 0.7459 - 2s/epoch - 24ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 2s - loss: 0.7483 - 2s/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 2s - loss: 0.7271 - 2s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 2s - loss: 0.7285 - 2s/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 2s - loss: 0.7232 - 2s/epoch - 24ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 2s - loss: 0.7247 - 2s/epoch - 24ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 2s - loss: 0.7234 - 2s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 2s - loss: 0.7176 - 2s/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 2s - loss: 0.7171 - 2s/epoch - 24ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 2s - loss: 0.7198 - 2s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 2s - loss: 0.7152 - 2s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 2s - loss: 0.7102 - 2s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 2s - loss: 0.7225 - 2s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 2s - loss: 0.7100 - 2s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 2s - loss: 0.7137 - 2s/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 2s - loss: 0.7133 - 2s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 2s - loss: 0.7073 - 2s/epoch - 24ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 2s - loss: 0.7054 - 2s/epoch - 24ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 2s - loss: 0.7070 - 2s/epoch - 24ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 2s - loss: 0.7207 - 2s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 2s - loss: 0.6879 - 2s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 2s - loss: 0.6990 - 2s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 2s - loss: 0.6963 - 2s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 2s - loss: 0.7001 - 2s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 2s - loss: 0.6933 - 2s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 2s - loss: 0.7068 - 2s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 2s - loss: 0.6965 - 2s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 2s - loss: 0.7026 - 2s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 2s - loss: 0.6920 - 2s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 2s - loss: 0.6923 - 2s/epoch - 25ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 2s - loss: 0.6887 - 2s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 2s - loss: 0.6869 - 2s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 2s - loss: 0.6861 - 2s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 2s - loss: 0.6871 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 2s - loss: 0.6845 - 2s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 2s - loss: 0.6952 - 2s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 2s - loss: 0.6832 - 2s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 2s - loss: 0.6811 - 2s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 2s - loss: 0.6753 - 2s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 2s - loss: 0.6789 - 2s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 2s - loss: 0.6770 - 2s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 2s - loss: 0.6758 - 2s/epoch - 27ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 2s - loss: 0.6690 - 2s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 2s - loss: 0.6791 - 2s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 2s - loss: 0.6669 - 2s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:47:37.871533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:47:39.159667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 4s - loss: 1.0735 - 4s/epoch - 61ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 2s - loss: 1.0561 - 2s/epoch - 25ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 2s - loss: 1.0280 - 2s/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 2s - loss: 0.9995 - 2s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 2s - loss: 0.9985 - 2s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 2s - loss: 0.9681 - 2s/epoch - 25ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 2s - loss: 0.9345 - 2s/epoch - 26ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 2s - loss: 0.9511 - 2s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 2s - loss: 0.9626 - 2s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 2s - loss: 0.9234 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 2s - loss: 0.8989 - 2s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 2s - loss: 0.8998 - 2s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 2s - loss: 0.8912 - 2s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 2s - loss: 0.8916 - 2s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 2s - loss: 0.8920 - 2s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 2s - loss: 0.8740 - 2s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 2s - loss: 0.8585 - 2s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 2s - loss: 0.8664 - 2s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 2s - loss: 0.8592 - 2s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 2s - loss: 0.8532 - 2s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 2s - loss: 0.8419 - 2s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 2s - loss: 0.8457 - 2s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 2s - loss: 0.8472 - 2s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 2s - loss: 0.8190 - 2s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 2s - loss: 0.8198 - 2s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 2s - loss: 0.8334 - 2s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 2s - loss: 0.8021 - 2s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 2s - loss: 0.8103 - 2s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 2s - loss: 0.8011 - 2s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 2s - loss: 0.7943 - 2s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 2s - loss: 0.8007 - 2s/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 2s - loss: 0.7793 - 2s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 2s - loss: 0.7904 - 2s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 2s - loss: 0.7912 - 2s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 2s - loss: 0.7782 - 2s/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 2s - loss: 0.8020 - 2s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 2s - loss: 0.7843 - 2s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 2s - loss: 0.7677 - 2s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 2s - loss: 0.7661 - 2s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 2s - loss: 0.7549 - 2s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 2s - loss: 0.7814 - 2s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 2s - loss: 0.7517 - 2s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 2s - loss: 0.7646 - 2s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 2s - loss: 0.7660 - 2s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 2s - loss: 0.7618 - 2s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 2s - loss: 0.7506 - 2s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 2s - loss: 0.7388 - 2s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 2s - loss: 0.7381 - 2s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 2s - loss: 0.7589 - 2s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 2s - loss: 0.7539 - 2s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 2s - loss: 0.7516 - 2s/epoch - 26ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 2s - loss: 0.7385 - 2s/epoch - 25ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 2s - loss: 0.7272 - 2s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 2s - loss: 0.7289 - 2s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 2s - loss: 0.7561 - 2s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 2s - loss: 0.7327 - 2s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 2s - loss: 0.7236 - 2s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 2s - loss: 0.7493 - 2s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 2s - loss: 0.7373 - 2s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 2s - loss: 0.7190 - 2s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 2s - loss: 0.7140 - 2s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 2s - loss: 0.7216 - 2s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 2s - loss: 0.7116 - 2s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 2s - loss: 0.7097 - 2s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 2s - loss: 0.7235 - 2s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 2s - loss: 0.7178 - 2s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 2s - loss: 0.7205 - 2s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 2s - loss: 0.7087 - 2s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 2s - loss: 0.7065 - 2s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 2s - loss: 0.7154 - 2s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 2s - loss: 0.7163 - 2s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 2s - loss: 0.7119 - 2s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 2s - loss: 0.6976 - 2s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 2s - loss: 0.7103 - 2s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 2s - loss: 0.6905 - 2s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 2s - loss: 0.6918 - 2s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 2s - loss: 0.7025 - 2s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 2s - loss: 0.6912 - 2s/epoch - 25ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 2s - loss: 0.6916 - 2s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 2s - loss: 0.6970 - 2s/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 2s - loss: 0.7096 - 2s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 2s - loss: 0.6945 - 2s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 2s - loss: 0.6883 - 2s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 2s - loss: 0.6978 - 2s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 2s - loss: 0.6853 - 2s/epoch - 26ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 2s - loss: 0.6878 - 2s/epoch - 26ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 2s - loss: 0.6875 - 2s/epoch - 25ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 2s - loss: 0.6790 - 2s/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 2s - loss: 0.6870 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 2s - loss: 0.6829 - 2s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 2s - loss: 0.6871 - 2s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 2s - loss: 0.6906 - 2s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 2s - loss: 0.6780 - 2s/epoch - 26ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 2s - loss: 0.6921 - 2s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 2s - loss: 0.6817 - 2s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 2s - loss: 0.6825 - 2s/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 2s - loss: 0.6758 - 2s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 2s - loss: 0.6699 - 2s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 2s - loss: 0.6667 - 2s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 2s - loss: 0.6741 - 2s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:50:21.025825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:50:22.378452: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 4s - loss: 1.0507 - 4s/epoch - 59ms/step\n",
      "Epoch 2/100\n",
      "64/64 - 2s - loss: 1.0358 - 2s/epoch - 27ms/step\n",
      "Epoch 3/100\n",
      "64/64 - 2s - loss: 0.9822 - 2s/epoch - 26ms/step\n",
      "Epoch 4/100\n",
      "64/64 - 2s - loss: 0.9815 - 2s/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "64/64 - 2s - loss: 0.9764 - 2s/epoch - 25ms/step\n",
      "Epoch 6/100\n",
      "64/64 - 2s - loss: 0.9478 - 2s/epoch - 26ms/step\n",
      "Epoch 7/100\n",
      "64/64 - 2s - loss: 0.9323 - 2s/epoch - 25ms/step\n",
      "Epoch 8/100\n",
      "64/64 - 2s - loss: 0.9116 - 2s/epoch - 25ms/step\n",
      "Epoch 9/100\n",
      "64/64 - 2s - loss: 0.8989 - 2s/epoch - 25ms/step\n",
      "Epoch 10/100\n",
      "64/64 - 2s - loss: 0.8929 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "64/64 - 2s - loss: 0.8944 - 2s/epoch - 25ms/step\n",
      "Epoch 12/100\n",
      "64/64 - 2s - loss: 0.8803 - 2s/epoch - 25ms/step\n",
      "Epoch 13/100\n",
      "64/64 - 2s - loss: 0.8590 - 2s/epoch - 25ms/step\n",
      "Epoch 14/100\n",
      "64/64 - 2s - loss: 0.8650 - 2s/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "64/64 - 2s - loss: 0.8647 - 2s/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "64/64 - 2s - loss: 0.8485 - 2s/epoch - 25ms/step\n",
      "Epoch 17/100\n",
      "64/64 - 2s - loss: 0.8399 - 2s/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "64/64 - 2s - loss: 0.8408 - 2s/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "64/64 - 2s - loss: 0.8478 - 2s/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "64/64 - 2s - loss: 0.8302 - 2s/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "64/64 - 2s - loss: 0.8325 - 2s/epoch - 25ms/step\n",
      "Epoch 22/100\n",
      "64/64 - 2s - loss: 0.8311 - 2s/epoch - 25ms/step\n",
      "Epoch 23/100\n",
      "64/64 - 2s - loss: 0.8212 - 2s/epoch - 25ms/step\n",
      "Epoch 24/100\n",
      "64/64 - 2s - loss: 0.8118 - 2s/epoch - 25ms/step\n",
      "Epoch 25/100\n",
      "64/64 - 2s - loss: 0.8136 - 2s/epoch - 25ms/step\n",
      "Epoch 26/100\n",
      "64/64 - 2s - loss: 0.8080 - 2s/epoch - 25ms/step\n",
      "Epoch 27/100\n",
      "64/64 - 2s - loss: 0.8037 - 2s/epoch - 25ms/step\n",
      "Epoch 28/100\n",
      "64/64 - 2s - loss: 0.8018 - 2s/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "64/64 - 2s - loss: 0.7996 - 2s/epoch - 25ms/step\n",
      "Epoch 30/100\n",
      "64/64 - 2s - loss: 0.7975 - 2s/epoch - 25ms/step\n",
      "Epoch 31/100\n",
      "64/64 - 2s - loss: 0.7889 - 2s/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "64/64 - 2s - loss: 0.7858 - 2s/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "64/64 - 2s - loss: 0.7870 - 2s/epoch - 25ms/step\n",
      "Epoch 34/100\n",
      "64/64 - 2s - loss: 0.7922 - 2s/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "64/64 - 2s - loss: 0.7786 - 2s/epoch - 26ms/step\n",
      "Epoch 36/100\n",
      "64/64 - 2s - loss: 0.7818 - 2s/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "64/64 - 2s - loss: 0.7840 - 2s/epoch - 25ms/step\n",
      "Epoch 38/100\n",
      "64/64 - 2s - loss: 0.7747 - 2s/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "64/64 - 2s - loss: 0.7684 - 2s/epoch - 25ms/step\n",
      "Epoch 40/100\n",
      "64/64 - 2s - loss: 0.7524 - 2s/epoch - 25ms/step\n",
      "Epoch 41/100\n",
      "64/64 - 2s - loss: 0.7526 - 2s/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "64/64 - 2s - loss: 0.7596 - 2s/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "64/64 - 2s - loss: 0.7480 - 2s/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "64/64 - 2s - loss: 0.7444 - 2s/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "64/64 - 2s - loss: 0.7385 - 2s/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "64/64 - 2s - loss: 0.7465 - 2s/epoch - 25ms/step\n",
      "Epoch 47/100\n",
      "64/64 - 2s - loss: 0.7568 - 2s/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "64/64 - 2s - loss: 0.7466 - 2s/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "64/64 - 2s - loss: 0.7491 - 2s/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "64/64 - 2s - loss: 0.7481 - 2s/epoch - 25ms/step\n",
      "Epoch 51/100\n",
      "64/64 - 2s - loss: 0.7448 - 2s/epoch - 25ms/step\n",
      "Epoch 52/100\n",
      "64/64 - 2s - loss: 0.7436 - 2s/epoch - 26ms/step\n",
      "Epoch 53/100\n",
      "64/64 - 2s - loss: 0.7354 - 2s/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "64/64 - 2s - loss: 0.7265 - 2s/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "64/64 - 2s - loss: 0.7350 - 2s/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "64/64 - 2s - loss: 0.7301 - 2s/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "64/64 - 2s - loss: 0.7257 - 2s/epoch - 25ms/step\n",
      "Epoch 58/100\n",
      "64/64 - 2s - loss: 0.7267 - 2s/epoch - 25ms/step\n",
      "Epoch 59/100\n",
      "64/64 - 2s - loss: 0.7227 - 2s/epoch - 25ms/step\n",
      "Epoch 60/100\n",
      "64/64 - 2s - loss: 0.7252 - 2s/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "64/64 - 2s - loss: 0.7094 - 2s/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "64/64 - 2s - loss: 0.7117 - 2s/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "64/64 - 2s - loss: 0.7123 - 2s/epoch - 25ms/step\n",
      "Epoch 64/100\n",
      "64/64 - 2s - loss: 0.7203 - 2s/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "64/64 - 2s - loss: 0.7102 - 2s/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "64/64 - 2s - loss: 0.7042 - 2s/epoch - 25ms/step\n",
      "Epoch 67/100\n",
      "64/64 - 2s - loss: 0.7098 - 2s/epoch - 25ms/step\n",
      "Epoch 68/100\n",
      "64/64 - 2s - loss: 0.7141 - 2s/epoch - 25ms/step\n",
      "Epoch 69/100\n",
      "64/64 - 2s - loss: 0.7083 - 2s/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "64/64 - 2s - loss: 0.7006 - 2s/epoch - 25ms/step\n",
      "Epoch 71/100\n",
      "64/64 - 2s - loss: 0.7018 - 2s/epoch - 25ms/step\n",
      "Epoch 72/100\n",
      "64/64 - 2s - loss: 0.7074 - 2s/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "64/64 - 2s - loss: 0.7025 - 2s/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "64/64 - 2s - loss: 0.7118 - 2s/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "64/64 - 2s - loss: 0.6987 - 2s/epoch - 25ms/step\n",
      "Epoch 76/100\n",
      "64/64 - 2s - loss: 0.6852 - 2s/epoch - 25ms/step\n",
      "Epoch 77/100\n",
      "64/64 - 2s - loss: 0.6956 - 2s/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "64/64 - 2s - loss: 0.6930 - 2s/epoch - 26ms/step\n",
      "Epoch 79/100\n",
      "64/64 - 2s - loss: 0.7045 - 2s/epoch - 25ms/step\n",
      "Epoch 80/100\n",
      "64/64 - 2s - loss: 0.6963 - 2s/epoch - 26ms/step\n",
      "Epoch 81/100\n",
      "64/64 - 2s - loss: 0.7004 - 2s/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "64/64 - 2s - loss: 0.6865 - 2s/epoch - 25ms/step\n",
      "Epoch 83/100\n",
      "64/64 - 2s - loss: 0.6955 - 2s/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "64/64 - 2s - loss: 0.6862 - 2s/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "64/64 - 2s - loss: 0.6938 - 2s/epoch - 25ms/step\n",
      "Epoch 86/100\n",
      "64/64 - 2s - loss: 0.6799 - 2s/epoch - 25ms/step\n",
      "Epoch 87/100\n",
      "64/64 - 2s - loss: 0.6949 - 2s/epoch - 26ms/step\n",
      "Epoch 88/100\n",
      "64/64 - 2s - loss: 0.6865 - 2s/epoch - 26ms/step\n",
      "Epoch 89/100\n",
      "64/64 - 2s - loss: 0.6752 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "64/64 - 2s - loss: 0.6872 - 2s/epoch - 25ms/step\n",
      "Epoch 91/100\n",
      "64/64 - 2s - loss: 0.6815 - 2s/epoch - 25ms/step\n",
      "Epoch 92/100\n",
      "64/64 - 2s - loss: 0.6833 - 2s/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "64/64 - 2s - loss: 0.6797 - 2s/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "64/64 - 2s - loss: 0.6750 - 2s/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "64/64 - 2s - loss: 0.6735 - 2s/epoch - 25ms/step\n",
      "Epoch 96/100\n",
      "64/64 - 2s - loss: 0.6681 - 2s/epoch - 26ms/step\n",
      "Epoch 97/100\n",
      "64/64 - 2s - loss: 0.6698 - 2s/epoch - 25ms/step\n",
      "Epoch 98/100\n",
      "64/64 - 2s - loss: 0.6759 - 2s/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "64/64 - 2s - loss: 0.6791 - 2s/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "64/64 - 2s - loss: 0.6657 - 2s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:53:05.112318: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24215686274509804\n"
     ]
    }
   ],
   "source": [
    "# print(optimized_params)\n",
    "# nn = models.NN(optimized_params)\n",
    "# print(cross_validation_score(nn, X_train, y_train))\n",
    "# with open('./config/NN-shallow.json', 'w') as f:\n",
    "#     json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-19 12:53:05,898]\u001b[0m A new study created in memory with name: no-name-d8c2c026-3a15-424e-a719-26972826fe2f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 12:53:08.761547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 - 9s - loss: 0.9233 - 9s/epoch - 163ms/step\n",
      "Epoch 2/100\n",
      "56/56 - 3s - loss: 0.8961 - 3s/epoch - 53ms/step\n",
      "Epoch 3/100\n",
      "56/56 - 3s - loss: 0.8811 - 3s/epoch - 53ms/step\n",
      "Epoch 4/100\n",
      "56/56 - 3s - loss: 0.8618 - 3s/epoch - 52ms/step\n",
      "Epoch 5/100\n",
      "56/56 - 3s - loss: 0.8558 - 3s/epoch - 51ms/step\n",
      "Epoch 6/100\n",
      "56/56 - 3s - loss: 0.8346 - 3s/epoch - 52ms/step\n",
      "Epoch 7/100\n",
      "56/56 - 3s - loss: 0.8056 - 3s/epoch - 52ms/step\n",
      "Epoch 8/100\n",
      "56/56 - 3s - loss: 0.8146 - 3s/epoch - 52ms/step\n",
      "Epoch 9/100\n",
      "56/56 - 3s - loss: 0.8092 - 3s/epoch - 51ms/step\n",
      "Epoch 10/100\n",
      "56/56 - 3s - loss: 0.7969 - 3s/epoch - 52ms/step\n",
      "Epoch 11/100\n",
      "56/56 - 3s - loss: 0.8059 - 3s/epoch - 52ms/step\n",
      "Epoch 12/100\n",
      "56/56 - 3s - loss: 0.7850 - 3s/epoch - 53ms/step\n",
      "Epoch 13/100\n",
      "56/56 - 3s - loss: 0.7815 - 3s/epoch - 54ms/step\n",
      "Epoch 14/100\n",
      "56/56 - 3s - loss: 0.7729 - 3s/epoch - 52ms/step\n",
      "Epoch 15/100\n",
      "56/56 - 3s - loss: 0.7631 - 3s/epoch - 51ms/step\n",
      "Epoch 16/100\n",
      "56/56 - 3s - loss: 0.7821 - 3s/epoch - 51ms/step\n",
      "Epoch 17/100\n",
      "56/56 - 3s - loss: 0.7685 - 3s/epoch - 51ms/step\n",
      "Epoch 18/100\n",
      "56/56 - 3s - loss: 0.7498 - 3s/epoch - 52ms/step\n",
      "Epoch 19/100\n",
      "56/56 - 3s - loss: 0.7595 - 3s/epoch - 52ms/step\n",
      "Epoch 20/100\n",
      "56/56 - 3s - loss: 0.7539 - 3s/epoch - 51ms/step\n",
      "Epoch 21/100\n",
      "56/56 - 3s - loss: 0.7595 - 3s/epoch - 51ms/step\n",
      "Epoch 22/100\n",
      "56/56 - 3s - loss: 0.7398 - 3s/epoch - 51ms/step\n",
      "Epoch 23/100\n",
      "56/56 - 3s - loss: 0.7400 - 3s/epoch - 51ms/step\n",
      "Epoch 24/100\n",
      "56/56 - 3s - loss: 0.7344 - 3s/epoch - 51ms/step\n",
      "Epoch 25/100\n",
      "56/56 - 3s - loss: 0.7341 - 3s/epoch - 51ms/step\n",
      "Epoch 26/100\n",
      "56/56 - 3s - loss: 0.7371 - 3s/epoch - 51ms/step\n",
      "Epoch 27/100\n",
      "56/56 - 3s - loss: 0.7357 - 3s/epoch - 51ms/step\n",
      "Epoch 28/100\n",
      "56/56 - 3s - loss: 0.7328 - 3s/epoch - 51ms/step\n",
      "Epoch 29/100\n",
      "56/56 - 3s - loss: 0.7330 - 3s/epoch - 51ms/step\n",
      "Epoch 30/100\n",
      "56/56 - 3s - loss: 0.7096 - 3s/epoch - 51ms/step\n",
      "Epoch 31/100\n",
      "56/56 - 3s - loss: 0.7232 - 3s/epoch - 51ms/step\n",
      "Epoch 32/100\n",
      "56/56 - 3s - loss: 0.7230 - 3s/epoch - 51ms/step\n",
      "Epoch 33/100\n",
      "56/56 - 3s - loss: 0.7100 - 3s/epoch - 51ms/step\n",
      "Epoch 34/100\n",
      "56/56 - 3s - loss: 0.7175 - 3s/epoch - 51ms/step\n",
      "Epoch 35/100\n",
      "56/56 - 3s - loss: 0.7108 - 3s/epoch - 51ms/step\n",
      "Epoch 36/100\n",
      "56/56 - 3s - loss: 0.7116 - 3s/epoch - 51ms/step\n",
      "Epoch 37/100\n",
      "56/56 - 3s - loss: 0.7098 - 3s/epoch - 51ms/step\n",
      "Epoch 38/100\n",
      "56/56 - 3s - loss: 0.7028 - 3s/epoch - 51ms/step\n",
      "Epoch 39/100\n",
      "56/56 - 3s - loss: 0.7072 - 3s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "56/56 - 3s - loss: 0.7062 - 3s/epoch - 51ms/step\n",
      "Epoch 41/100\n",
      "56/56 - 3s - loss: 0.7086 - 3s/epoch - 51ms/step\n",
      "Epoch 42/100\n",
      "56/56 - 3s - loss: 0.6983 - 3s/epoch - 51ms/step\n",
      "Epoch 43/100\n",
      "56/56 - 3s - loss: 0.7093 - 3s/epoch - 51ms/step\n",
      "Epoch 44/100\n",
      "56/56 - 3s - loss: 0.6993 - 3s/epoch - 51ms/step\n",
      "Epoch 45/100\n",
      "56/56 - 3s - loss: 0.6907 - 3s/epoch - 51ms/step\n",
      "Epoch 46/100\n",
      "56/56 - 3s - loss: 0.6963 - 3s/epoch - 51ms/step\n",
      "Epoch 47/100\n",
      "56/56 - 3s - loss: 0.6935 - 3s/epoch - 51ms/step\n",
      "Epoch 48/100\n",
      "56/56 - 3s - loss: 0.6832 - 3s/epoch - 51ms/step\n",
      "Epoch 49/100\n",
      "56/56 - 3s - loss: 0.6870 - 3s/epoch - 51ms/step\n",
      "Epoch 50/100\n",
      "56/56 - 3s - loss: 0.6871 - 3s/epoch - 51ms/step\n",
      "Epoch 51/100\n",
      "56/56 - 3s - loss: 0.6842 - 3s/epoch - 52ms/step\n",
      "Epoch 52/100\n",
      "56/56 - 3s - loss: 0.6910 - 3s/epoch - 51ms/step\n",
      "Epoch 53/100\n",
      "56/56 - 3s - loss: 0.6832 - 3s/epoch - 51ms/step\n",
      "Epoch 54/100\n",
      "56/56 - 3s - loss: 0.6788 - 3s/epoch - 51ms/step\n",
      "Epoch 55/100\n",
      "56/56 - 3s - loss: 0.6807 - 3s/epoch - 51ms/step\n",
      "Epoch 56/100\n",
      "56/56 - 3s - loss: 0.6857 - 3s/epoch - 51ms/step\n",
      "Epoch 57/100\n",
      "56/56 - 3s - loss: 0.6813 - 3s/epoch - 52ms/step\n",
      "Epoch 58/100\n",
      "56/56 - 3s - loss: 0.6850 - 3s/epoch - 51ms/step\n",
      "Epoch 59/100\n",
      "56/56 - 3s - loss: 0.6770 - 3s/epoch - 51ms/step\n",
      "Epoch 60/100\n",
      "56/56 - 3s - loss: 0.6746 - 3s/epoch - 51ms/step\n",
      "Epoch 61/100\n",
      "56/56 - 3s - loss: 0.6705 - 3s/epoch - 51ms/step\n",
      "Epoch 62/100\n",
      "56/56 - 3s - loss: 0.6748 - 3s/epoch - 51ms/step\n",
      "Epoch 63/100\n",
      "56/56 - 3s - loss: 0.6806 - 3s/epoch - 51ms/step\n",
      "Epoch 64/100\n",
      "56/56 - 3s - loss: 0.6789 - 3s/epoch - 51ms/step\n",
      "Epoch 65/100\n",
      "56/56 - 3s - loss: 0.6720 - 3s/epoch - 51ms/step\n",
      "Epoch 66/100\n",
      "56/56 - 3s - loss: 0.6725 - 3s/epoch - 51ms/step\n",
      "Epoch 67/100\n",
      "56/56 - 3s - loss: 0.6745 - 3s/epoch - 51ms/step\n",
      "Epoch 68/100\n",
      "56/56 - 3s - loss: 0.6600 - 3s/epoch - 51ms/step\n",
      "Epoch 69/100\n",
      "56/56 - 3s - loss: 0.6670 - 3s/epoch - 51ms/step\n",
      "Epoch 70/100\n",
      "56/56 - 3s - loss: 0.6606 - 3s/epoch - 51ms/step\n",
      "Epoch 71/100\n",
      "56/56 - 3s - loss: 0.6716 - 3s/epoch - 51ms/step\n",
      "Epoch 72/100\n",
      "56/56 - 3s - loss: 0.6634 - 3s/epoch - 51ms/step\n",
      "Epoch 73/100\n",
      "56/56 - 3s - loss: 0.6636 - 3s/epoch - 51ms/step\n",
      "Epoch 74/100\n",
      "56/56 - 3s - loss: 0.6573 - 3s/epoch - 51ms/step\n",
      "Epoch 75/100\n",
      "56/56 - 3s - loss: 0.6629 - 3s/epoch - 55ms/step\n",
      "Epoch 76/100\n",
      "56/56 - 3s - loss: 0.6629 - 3s/epoch - 57ms/step\n",
      "Epoch 77/100\n",
      "56/56 - 3s - loss: 0.6701 - 3s/epoch - 57ms/step\n",
      "Epoch 78/100\n",
      "56/56 - 3s - loss: 0.6626 - 3s/epoch - 55ms/step\n",
      "Epoch 79/100\n",
      "56/56 - 3s - loss: 0.6596 - 3s/epoch - 52ms/step\n",
      "Epoch 80/100\n",
      "56/56 - 3s - loss: 0.6612 - 3s/epoch - 52ms/step\n",
      "Epoch 81/100\n",
      "56/56 - 3s - loss: 0.6576 - 3s/epoch - 54ms/step\n",
      "Epoch 82/100\n",
      "56/56 - 3s - loss: 0.6635 - 3s/epoch - 52ms/step\n",
      "Epoch 83/100\n",
      "56/56 - 3s - loss: 0.6520 - 3s/epoch - 52ms/step\n",
      "Epoch 84/100\n",
      "56/56 - 3s - loss: 0.6559 - 3s/epoch - 54ms/step\n",
      "Epoch 85/100\n",
      "56/56 - 3s - loss: 0.6549 - 3s/epoch - 52ms/step\n",
      "Epoch 86/100\n",
      "56/56 - 3s - loss: 0.6575 - 3s/epoch - 52ms/step\n",
      "Epoch 87/100\n",
      "56/56 - 3s - loss: 0.6511 - 3s/epoch - 55ms/step\n",
      "Epoch 88/100\n",
      "56/56 - 3s - loss: 0.6465 - 3s/epoch - 56ms/step\n",
      "Epoch 89/100\n",
      "56/56 - 3s - loss: 0.6510 - 3s/epoch - 54ms/step\n",
      "Epoch 90/100\n",
      "56/56 - 3s - loss: 0.6490 - 3s/epoch - 56ms/step\n",
      "Epoch 91/100\n",
      "56/56 - 3s - loss: 0.6488 - 3s/epoch - 58ms/step\n",
      "Epoch 92/100\n",
      "56/56 - 3s - loss: 0.6510 - 3s/epoch - 55ms/step\n",
      "Epoch 93/100\n",
      "56/56 - 3s - loss: 0.6570 - 3s/epoch - 54ms/step\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m nn \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mNN({})\n\u001b[0;32m----> 2\u001b[0m optimized_params \u001b[39m=\u001b[39m beyesian_optimization(nn, X_train, y_train, {\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m10\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: [\u001b[39m0.00001\u001b[39;49m, \u001b[39m0.9\u001b[39;49m],\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39munits\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m20\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mnb_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m100\u001b[39;49m\n\u001b[1;32m      7\u001b[0m }, \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Github/Signate/576-Census/models/tuning.py:37\u001b[0m, in \u001b[0;36mbeyesian_optimization\u001b[0;34m(model, X, y, params, n_trials)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=33'>34</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m score\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=35'>36</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(sampler\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mRandomSampler(seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m---> <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=36'>37</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mn_trials)\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=38'>39</a>\u001b[0m res \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=391'>392</a>\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=392'>393</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=393'>394</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=394'>395</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=395'>396</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=396'>397</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=397'>398</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=399'>400</a>\u001b[0m _optimize(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=400'>401</a>\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=401'>402</a>\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=402'>403</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=403'>404</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=404'>405</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=405'>406</a>\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=406'>407</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=407'>408</a>\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=408'>409</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/study.py?line=409'>410</a>\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=63'>64</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=64'>65</a>\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=65'>66</a>\u001b[0m         _optimize_sequential(\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=66'>67</a>\u001b[0m             study,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=67'>68</a>\u001b[0m             func,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=68'>69</a>\u001b[0m             n_trials,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=69'>70</a>\u001b[0m             timeout,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=70'>71</a>\u001b[0m             catch,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=71'>72</a>\u001b[0m             callbacks,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=72'>73</a>\u001b[0m             gc_after_trial,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=73'>74</a>\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=74'>75</a>\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=75'>76</a>\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=76'>77</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=77'>78</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=78'>79</a>\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=159'>160</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=161'>162</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=162'>163</a>\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=163'>164</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=164'>165</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=209'>210</a>\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=211'>212</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=212'>213</a>\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=213'>214</a>\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=214'>215</a>\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/optuna/study/_optimize.py?line=215'>216</a>\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Desktop/Github/Signate/576-Census/models/tuning.py:30\u001b[0m, in \u001b[0;36mbeyesian_optimization.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=27'>28</a>\u001b[0m \u001b[39m#  model\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m optuna_params\n\u001b[0;32m---> <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=30'>31</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_valid)\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/tuning.py?line=31'>32</a>\u001b[0m y_pred \u001b[39m=\u001b[39m (y_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Github/Signate/576-Census/models/models.py:81\u001b[0m, in \u001b[0;36mNN.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/models.py?line=77'>78</a>\u001b[0m model\u001b[39m.\u001b[39madd(Activation(\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/models.py?line=78'>79</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madagrad\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///~/Desktop/Github/Signate/576-Census/models/models.py?line=80'>81</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mtransform(X_train), y_train,\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/models.py?line=81'>82</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49mnb_epoch, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='file:///~/Desktop/Github/Signate/576-Census/models/models.py?line=82'>83</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/tensorflow26/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nn = models.NN({})\n",
    "# optimized_params = beyesian_optimization(nn, X_train, y_train, {\n",
    "#     'layers': 10,\n",
    "#     'dropout': [0.00001, 0.9],\n",
    "#     'units': 20,\n",
    "#     'nb_epoch': 100\n",
    "# }, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(optimized_params)\n",
    "# nn = models.NN(optimized_params)\n",
    "# # nn.save_model('./config/NN-deep.h5')\n",
    "# print(cross_validation_score(nn, X_train, y_train))\n",
    "# with open('./config/NN-deep.json', 'w') as f:\n",
    "#     json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 13:57:11.138947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 13:58:06.772865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 13:58:07.618520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 13:59:03.844028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 13:59:04.614842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:00:00.333078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:00:01.139263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:00:57.400300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:00:58.163598: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:01:52.463655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8644117647058823\n",
      "{'patience': 30, 'layers': 2, 'dropout': 0.1, 'units': 100, 'nb_epoch': 100, 'batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "optimized_params = {\n",
    "    'patience': 30,\n",
    "    'layers': 2,\n",
    "    'dropout': 0.1,\n",
    "    'units': 100,\n",
    "    'nb_epoch': 100,\n",
    "    'batch_size': 256\n",
    "}\n",
    "nn = models.NN(optimized_params)\n",
    "print(cross_validation_score(nn, X_train, y_train))\n",
    "print(optimized_params)\n",
    "with open('./config/NN-shallow.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 14:21:22.759813: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:29:11.186030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:29:13.598560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:38:13.296307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:38:19.605740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:46:15.624204: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:46:18.055222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:55:57.741604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 14:56:00.231219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-19 15:04:43.158846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696078431372549\n",
      "{'patience': 30, 'layers': 8, 'dropout': 0.1, 'units': 100, 'nb_epoch': 1000, 'batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "optimized_params = {\n",
    "    'patience': 30,\n",
    "    'layers': 8,\n",
    "    'dropout': 0.1,\n",
    "    'units': 100,\n",
    "    'nb_epoch': 1000,\n",
    "    'batch_size': 256\n",
    "}\n",
    "nn = models.NN(optimized_params)\n",
    "print(cross_validation_score(nn, X_train, y_train))\n",
    "print(optimized_params)\n",
    "with open('./config/NN-deep.json', 'w') as f:\n",
    "    json.dump(optimized_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3f91d3689ed9f35fe62b472acb20385518ac1a4462c3f395fef40efd7e4015f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('matlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
